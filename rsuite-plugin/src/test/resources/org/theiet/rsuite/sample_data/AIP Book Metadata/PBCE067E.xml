<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE ebook PUBLIC "-//AIP//DTD XML Book Setup Module 1.0//EN" "AIPbookxml1.dtd">
<ebook xmlns:m="http://www.w3.org/1998/Math/MathML">
  <book-metadata>
    <book-identifiers>
      <bookid>PBCE067E</bookid>
      <doi>10.1049/PBCE067E</doi>
      <isbn13>9780863414534</isbn13>
      <isbn-eb>9780863411588</isbn-eb>
      <customerid>
        <identifier-name>IET</identifier-name>
        <identifier-value>PBCE0670</identifier-value>
      </customerid>
      <iet-subs>CE</iet-subs>
    </book-identifiers>
    <titlegrp>
      <title>Motion Vision: design of compact motion sensing solutions for navigation of autonomous systems</title>
      <search-title>Motion Vision: design of compact motion sensing solutions for navigation of autonomous systems</search-title>
    </titlegrp>
    <pubinfo>
      <numpages>456</numpages>
      <publication-date day="01" month="01" year="2005"></publication-date>
      <publisher-group>
        <ownerid>IET</ownerid>
        <publisher>Institution of Engineering and Technology</publisher>
      </publisher-group>
      <cpyrt>
        <cpyrtdate date="2005"/>
        <cpyrtholder>Institution of Engineering and Technology</cpyrtholder>
        <cpyrtstmt>All rights reserved. No part of this publication may be reproduced or distributed in any form or by any means without written permission of the  publisher</cpyrtstmt>
      </cpyrt>
      <price-model type="book-chapter"/>
    </pubinfo>
    <authgrp>
      <author>
        <fname>J.</fname><surname>Kolodko</surname>
        <fullname>J. Kolodko</fullname>
      </author>
      <author>
        <fname>L.</fname><surname>Vlacic</surname>
        <fullname>L. Vlacic</fullname>
      </author>
    </authgrp>
    <pubdesc>
      <p>Segmenting the environment surrounding an autonomous vehicle into coherently moving regions is a vital first step towards intelligent autonomous navigation. Without this temporal information, navigation becomes a simple obstacle avoidance scheme that is inappropriate in highly dynamic environments such as roadways and places where many people congregate. The book begins by looking at the problem of motion estimation from biological, algorithmic and digital perspectives. It goes on to describe an algorithm that fits with the motion processing model, and hardware and software constraints. This algorithm is based on the optical flow constraint equation and introduces range information to resolve the depth-velocity ambiguity, which is critical for autonomous navigation. Finally, implementation of the algorithm in digital hardware is described in detail, covering both the initial motion processing model and the chosen hardware platforms, and the global functional structure of the system.</p>
    </pubdesc>
    <abstract>
      <p>This book is divided into eight sections and four parts. Chapter 1 of the paper includes introduction of the book. Chapter 2, discusses motion estimation theory. (Chapter 3) elaborates motion estimation problem. Chapter 4 is devoted to consideration of the issue of real-time motion estimation in the context of autonomous navigation. In Chapter 5 motion estimation algorithm is considered in detail. In Chapter 6 the VHDL hardware description language is introduced, which is commonly used in FPGA design. Chapter 7 leaves the details of VHDL behind and considers design of sensor and the specific issues that arose in the development of our sensor.</p>
    </abstract>
    <vocabs>
      <classification-codes source="Inspec-class">
        <compound-classification-code><compound-classification-code-part type="code">B7230</compound-classification-code-part><compound-classification-code-part type="text">Sensing devices and transducers</compound-classification-code-part></compound-classification-code>
      </classification-codes>
      <keywords source="Inspec">
        <keyword source="Inspec">field programmable gate arrays</keyword>
        <keyword source="Inspec">hardware description languages</keyword>
        <keyword source="Inspec">motion estimation</keyword>
        <keyword source="Inspec">radionavigation</keyword>
        <keyword source="Inspec">sensors</keyword>
      </keywords>
      <keywords source="uncontrolled">
        <keyword source="uncontrolled">motion vision</keyword>
        <keyword source="uncontrolled">motion sensing solution</keyword>
        <keyword source="uncontrolled">autonomous system</keyword>
        <keyword source="uncontrolled">motion estimation theory</keyword>
        <keyword source="uncontrolled">real-time motion estimation problem</keyword>
        <keyword source="uncontrolled">autonomous navigation</keyword>
        <keyword source="uncontrolled">motion estimation algorithm</keyword>
        <keyword source="uncontrolled">VHDL hardware description language</keyword>
        <keyword source="uncontrolled">FPGA design</keyword>
        <keyword source="uncontrolled">sensor design</keyword>
      </keywords>
      <tia>field programmable gate arrays, hardware description languages, motion estimation, radionavigation, sensors</tia>
      <booktype>Control Engineering</booktype>
    </vocabs>
  </book-metadata>
  <body>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE067E_frontmatter</content-item-id>
          <doi>10.1049/PBCE067E_fm</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Front Matter</title>
          <search-title>Front Matter</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>front matter</content-item-type>
          <bookseq>1</bookseq>
          <section-head level="1">Preface</section-head>
          <section-head level="1">List of abbreviations</section-head>
          <section-head level="1">Symbols</section-head>
          <section-head level="1">Typographical conventions</section-head>
          <section-head level="1">Acknowledgements</section-head>
        </content-item-pubinfo>
        <funding-grp><access type="free"/></funding-grp>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE067E_ch1</content-item-id>
          <doi>10.1049/PBCE067E_ch1</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Introduction</title>
          <search-title>Introduction</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>chapter</content-item-type>
          <bookseq>2</bookseq>
          <item-num>1</item-num>
          <section-head level="1">1.1 The intelligent motion measuring sensor</section-head>
          <section-head level="2">1.1.1 Inputs and outputs</section-head>
          <section-head level="2">1.1.2 Real-time motion estimation</section-head>
          <section-head level="2">1.1.3 The motion estimation algorithm</section-head>
          <section-head level="2">1.1.4 The prototype sensor</section-head>
          <fpage>1</fpage>
          <lpage>8</lpage>
          <numpages>8</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>For some time we have been dealing with the design and development of cooperative autonomous vehicles. That is, we build vehicles that are not only intelligent in themselves but that can also explicitly cooperate with other autonomous vehicles so that both the individual and shared goals of each vehicle can be expediently achieved. In the road environment this includes the ability to perform driving manoeuvres such as traversal of unsignalised intersections, cooperative overtaking, cooperative formation driving, distance control, stop and go cruise control, intelligent speed adaptation, etc. Responding to the need for a source of motion information, we set out to develop a prototype intelligent sensor. This sensor was to provide timely information about the motion in the environment assuming that all motion occurs on a smooth ground plane. In order to have a compact sensing solution, we decided to implement our sensor using Field Programmable Gate Array (FPGA) technology. This, in principle, allowed us to incorporate all processing and interface logic in a single chip the only external devices are memory, power supplies and sensors.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">A0670D</compound-classification-code-part><compound-classification-code-part type="text">Sensing and detecting devices</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">cooperative systems</keyword>
            <keyword source="Inspec">field programmable gate arrays</keyword>
            <keyword source="Inspec">intelligent sensors</keyword>
            <keyword source="Inspec">microprocessor chips</keyword>
            <keyword source="Inspec">mobile robots</keyword>
            <keyword source="Inspec">motion measurement</keyword>
            <keyword source="Inspec">vehicles</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">intelligent motion measuring sensor</keyword>
            <keyword source="uncontrolled">motion information source</keyword>
            <keyword source="uncontrolled">smooth ground plane</keyword>
            <keyword source="uncontrolled">field programmable gate arrays</keyword>
            <keyword source="uncontrolled">FPGA</keyword>
            <keyword source="uncontrolled">interface logic</keyword>
            <keyword source="uncontrolled">cooperative autonomous vehicle</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE067E_ch2</content-item-id>
          <doi>10.1049/PBCE067E_ch2</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Mathematical preliminaries</title>
          <search-title>Mathematical preliminaries</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>chapter</content-item-type>
          <bookseq>3</bookseq>
          <item-num>2</item-num>
          <supertitle1>Part 1: Background</supertitle1>
          <section-head level="1">2.1 Basic concepts in probability</section-head>
          <section-head level="2">2.1.1 Experiments and trials</section-head>
          <section-head level="2">2.1.2 Sample space and outcome</section-head>
          <section-head level="2">2.1.3 Event</section-head>
          <section-head level="2">2.1.4 Computation of probability</section-head>
          <section-head level="2">2.1.5 Conditional probability</section-head>
          <section-head level="2">2.1.6 Total probability</section-head>
          <section-head level="2">2.1.7 Complement</section-head>
          <section-head level="2">2.1.8 OR</section-head>
          <section-head level="2">2.1.9 AND</section-head>
          <section-head level="2">2.1.10 Independent events</section-head>
          <section-head level="2">2.1.11 Bayes theorem</section-head>
          <section-head level="2">2.1.12 Order statistics</section-head>
          <section-head level="2">2.1.13 Random variable</section-head>
          <section-head level="2">2.1.14 Probability Density Function (PDF)</section-head>
          <section-head level="2">2.1.15 Cumulative Distribution Function (CDF)</section-head>
          <section-head level="2">2.1.16 Joint distribution functions</section-head>
          <section-head level="2">2.1.17 Marginal distribution function</section-head>
          <section-head level="2">2.1.18 Independent, identically distributed (iid)</section-head>
          <section-head level="2">2.1.19 Gaussian distribution and the central limit theorem</section-head>
          <section-head level="2">2.1.20 Random or stochastic processes</section-head>
          <section-head level="2">2.1.21 Stationary processes</section-head>
          <section-head level="2">2.1.22 Average</section-head>
          <section-head level="2">2.1.23 Variance</section-head>
          <section-head level="2">2.1.24 Expectation</section-head>
          <section-head level="2">2.1.25 Likelihood</section-head>
          <section-head level="1">2.2 Simple estimation problems</section-head>
          <section-head level="2">2.2.1 Linear regression</section-head>
          <section-head level="2">2.2.2 Solving linear regression problems</section-head>
          <section-head level="2">2.2.3 The Hough transform</section-head>
          <section-head level="2">2.2.4 Solving Hough transform problems</section-head>
          <section-head level="2">2.2.5 Multiple linear regression and regularisation</section-head>
          <section-head level="2">2.2.6 Solving the membrane model</section-head>
          <section-head level="2">2.2.7 Location estimates</section-head>
          <section-head level="2">2.2.8 Solving location estimation problems</section-head>
          <section-head level="2">2.2.9 Properties of simple estimators</section-head>
          <section-head level="1">2.3 Robust estimation</section-head>
          <section-head level="2">2.3.1 Outliers and leverage points</section-head>
          <section-head level="2">2.3.2 Properties of robust estimators</section-head>
          <section-head level="2">2.3.3 Some robust estimators</section-head>
          <fpage>11</fpage>
          <lpage>62</lpage>
          <numpages>52</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>Problems requiring a best guess for the value of some parameters based on noisy input data are estimation problems. Alternatively, you might view estimation problems as problems where you try to characterise a dataset using a mathematical construct such as a point or a line. This chapter is intended as a self-contained introduction to the basic concepts in the field of linear estimation. Assuch, it will give you an understanding of the analysis in the following chapters where we focus specifically on motion estimation. The discussion here is quite informal: our aim is to introduce the broad ideas of estimation-more detail is available from avast range of sources [64,122,148,201,239,267,303]. This chapter begins with a brief introduction to probability theory and some key terms before moving onto the basics of estimation, which then allows us to spring into the field of robust estimation. It is assumed you are familiar with basic calculus.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">B6135</compound-classification-code-part><compound-classification-code-part type="text">Optical, image and video signal processing</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">calculus</keyword>
            <keyword source="Inspec">estimation theory</keyword>
            <keyword source="Inspec">motion estimation</keyword>
            <keyword source="Inspec">probability</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">mathematical preliminary</keyword>
            <keyword source="uncontrolled">linear estimation</keyword>
            <keyword source="uncontrolled">motion estimation</keyword>
            <keyword source="uncontrolled">probability theory</keyword>
            <keyword source="uncontrolled">robust estimation</keyword>
            <keyword source="uncontrolled">calculus</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE067E_ch3</content-item-id>
          <doi>10.1049/PBCE067E_ch3</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Motion estimation</title>
          <search-title>Motion estimation</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>chapter</content-item-type>
          <bookseq>4</bookseq>
          <item-num>3</item-num>
          <supertitle1>Part 1: Background</supertitle1>
          <section-head level="1">3.1 The motion estimation problem</section-head>
          <section-head level="1">3.2 Visual motion estimation</section-head>
          <section-head level="2">3.2.1 Brightness constancy</section-head>
          <section-head level="2">3.2.2 Background subtraction and surveillance</section-head>
          <section-head level="2">3.2.3 Gradient based motion estimation</section-head>
          <section-head level="2">3.2.4 Displaced frame difference</section-head>
          <section-head level="2">3.2.5 Variations of the OFCE</section-head>
          <section-head level="2">3.2.6 Token based motion estimation</section-head>
          <section-head level="2">3.2.7 Frequency domain motion estimation</section-head>
          <section-head level="2">3.2.8 Multiple motions</section-head>
          <section-head level="1">3.3 Temporal integration</section-head>
          <section-head level="1">3.4 Alternate motion estimation techniques</section-head>
          <section-head level="1">3.5 Motion estimation hardware</section-head>
          <section-head level="1">3.6 Proposed motion sensor</section-head>
          <fpage>63</fpage>
          <lpage>100</lpage>
          <numpages>38</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>This chapter discusses the motion estimation. Motion 'sensing' has been widely studied both in computational contexts and biological contexts. Experiments conducted by Exner as far back as 1875 showed the ability of the human visual system to detect motion as a fundamental quantity. In this experiment, the timing of a series of electrical spark generators could be controlled. With correct timing, observers would see a single moving spark rather than a series of individual sparks. Computational studies of motion sensing have appeared more recently (most prominently since the 1970s) as computing power has increased.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">A4280Q</compound-classification-code-part><compound-classification-code-part type="text">Image detectors, convertors, and intensifiers</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">electric generators</keyword>
            <keyword source="Inspec">image sensors</keyword>
            <keyword source="Inspec">motion estimation</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">motion estimation</keyword>
            <keyword source="uncontrolled">human visual system</keyword>
            <keyword source="uncontrolled">motion detection</keyword>
            <keyword source="uncontrolled">electrical spark generator</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE067E_ch4</content-item-id>
          <doi>10.1049/PBCE067E_ch4</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Real-time motion processing</title>
          <search-title>Real-time motion processing</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>chapter</content-item-type>
          <bookseq>5</bookseq>
          <item-num>4</item-num>
          <supertitle1>Part2: Algorithm development</supertitle1>
          <section-head level="1">4.1 Frequency domain analysis of image motion</section-head>
          <section-head level="1">4.2 Rigid body motion and the pinhole camera model</section-head>
          <section-head level="1">4.3 Linking temporal aliasing to the safety margin</section-head>
          <section-head level="1">4.4 Scale space</section-head>
          <section-head level="1">4.5 Dynamic scale space</section-head>
          <section-head level="1">4.6 Issues surrounding a dynamic scale space</section-head>
          <fpage>103</fpage>
          <lpage>116</lpage>
          <numpages>14</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>The meaning of real-time depends on the application, however, it usually implies that processing is performed quickly with respect to the dynamics of the system under consideration. When estimating motion for autonomous navigation, there are two constraints that define the meaning of 'real-time'. Both constraints derive from the need to accurately capture environmental dynamics. The first limit is related to the imaging system and the second is imposed by the navigation problem. Temporal image sampling must occur sufficiently quickly to avoid temporal aliasing. Motion processing must proceed with an update rate and latency that ensures navigation decisions are made using the true current state of the environment. In this section it will be shown how scale space can be used to avoid temporal aliasing and that the inclusion of range information in scale space leads to a dynamic scale space which removes the overhead associated with more traditional approaches.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">B6135</compound-classification-code-part><compound-classification-code-part type="text">Optical, image and video signal processing</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">antialiasing</keyword>
            <keyword source="Inspec">distance measurement</keyword>
            <keyword source="Inspec">image sampling</keyword>
            <keyword source="Inspec">motion estimation</keyword>
            <keyword source="Inspec">navigation</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">real-time motion processing</keyword>
            <keyword source="uncontrolled">motion estimation</keyword>
            <keyword source="uncontrolled">autonomous navigation</keyword>
            <keyword source="uncontrolled">temporal image sampling</keyword>
            <keyword source="uncontrolled">temporal aliasing</keyword>
            <keyword source="uncontrolled">range information</keyword>
            <keyword source="uncontrolled">dynamic scale space</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE067E_ch5</content-item-id>
          <doi>10.1049/PBCE067E_ch5</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Motion estimation for autonomous navigation</title>
          <search-title>Motion estimation for autonomous navigation</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>chapter</content-item-type>
          <bookseq>6</bookseq>
          <item-num>5</item-num>
          <supertitle1>Part2: Algorithm development</supertitle1>
          <section-head level="1">5.1 Assumptions, requirements and principles</section-head>
          <section-head level="2">5.1.1 Application</section-head>
          <section-head level="2">5.1.2 Data sources</section-head>
          <section-head level="2">5.1.3 Motion</section-head>
          <section-head level="2">5.1.4 Environment</section-head>
          <section-head level="1">5.2 The motion estimation algorithm</section-head>
          <section-head level="2">5.2.1 Inputs and outputs</section-head>
          <section-head level="2">5.2.2 Constraint equation</section-head>
          <section-head level="2">5.2.3 Derivative estimation - practicalities</section-head>
          <section-head level="2">5.2.4 Effect of illumination change</section-head>
          <section-head level="2">5.2.5 Robust average</section-head>
          <section-head level="2">5.2.6 Comparing our robust average to other techniques</section-head>
          <section-head level="2">5.2.7 Monte Carlo study of the LTSV estimator</section-head>
          <section-head level="2">5.2.8 Computational complexity</section-head>
          <section-head level="2">5.2.9 Dynamic scale space implementation</section-head>
          <section-head level="2">5.2.10 Temporal integration implementation</section-head>
          <section-head level="2">5.2.11 The motion estimation algorithm</section-head>
          <section-head level="2">5.2.12 Simulation results</section-head>
          <section-head level="1">5.3 Navigation using the motion estimate</section-head>
          <fpage>117</fpage>
          <lpage>170</lpage>
          <numpages>54</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>The byline for this ehapter eloquently summarises our approach to motion estimation: it must happen quickly and it must happen without regard to any ancillary description of the environment. To avoid a moving object, all that is required is to know its location and approximate velocity knowing what the object is. its colour or its features is not necessary in this process. We treat motion as a fundamental quantity that is measured as directly as possible. This naturally leads to the gradient based methods, where the only intermediate description of the visible world consists of the intensity derivatives. Alterna tive motion estimation techniques require more complex intermediate descriptors: frequency domain techniques require sets of filter banks or Fourier transforms, and token based methods require explicit extraction of some type of structure from the world. This chapter draws together gradient based motion estimation, the rigid body motion model, dynamic scale space and a set of environmental assumptions to create a simple motion estimation algorithm. The resulting algorithm determines quickly the piecewise projection of relative three-dimensional translational motion onto the camera's X axis.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">B6330</compound-classification-code-part><compound-classification-code-part type="text">Radionavigation and direction finding</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">channel bank filters</keyword>
            <keyword source="Inspec">Fourier transforms</keyword>
            <keyword source="Inspec">frequency-domain analysis</keyword>
            <keyword source="Inspec">gradient methods</keyword>
            <keyword source="Inspec">motion estimation</keyword>
            <keyword source="Inspec">navigation</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">autonomous navigation</keyword>
            <keyword source="uncontrolled">frequency domain techniques</keyword>
            <keyword source="uncontrolled">filter banks</keyword>
            <keyword source="uncontrolled">Fourier transforms</keyword>
            <keyword source="uncontrolled">token based methods</keyword>
            <keyword source="uncontrolled">gradient based motion estimation</keyword>
            <keyword source="uncontrolled">three-dimensional translational motion</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE067E_ch6</content-item-id>
          <doi>10.1049/PBCE067E_ch6</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Digital design</title>
          <search-title>Digital design</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>chapter</content-item-type>
          <bookseq>7</bookseq>
          <item-num>6</item-num>
          <supertitle1>Part3: Hardware</supertitle1>
          <section-head level="1">6.1 What is an FPGA?</section-head>
          <section-head level="1">6.2 How do I specify what my FPGA does?</section-head>
          <section-head level="1">6.3 The FPGA design process in a nutshell</section-head>
          <section-head level="1">6.4 Time</section-head>
          <section-head level="1">6.5 Our design approach</section-head>
          <section-head level="1">6.6 Introducing VHDL</section-head>
          <section-head level="2">6.6.1 VHDL entities and architectures</section-head>
          <section-head level="2">6.6.2 VHDL types and libraries</section-head>
          <section-head level="2">6.6.3 Concurrent and sequential statements</section-head>
          <section-head level="2">6.6.4 Inference</section-head>
          <section-head level="1">6.7 Timing constraints</section-head>
          <section-head level="1">6.8 General design tips</section-head>
          <section-head level="2">6.8.1 Synchronisation and metastability</section-head>
          <section-head level="2">6.8.2 Limit nesting of if statements</section-head>
          <section-head level="2">6.8.3 Tristate buffers for large multiplexers</section-head>
          <section-head level="2">6.8.4 Tristate buffers</section-head>
          <section-head level="2">6.8.5 Don't gate clocks</section-head>
          <section-head level="2">6.8.6 Register outputs for all blocks</section-head>
          <section-head level="2">6.8.7 Counters</section-head>
          <section-head level="2">6.8.8 Special features</section-head>
          <section-head level="2">6.8.9 Sequential pipelining</section-head>
          <section-head level="2">6.8.10 Use of hierarchy</section-head>
          <section-head level="2">6.8.11 Parentheses</section-head>
          <section-head level="2">6.8.12 Bit width</section-head>
          <section-head level="2">6.8.13 Initialisation</section-head>
          <section-head level="2">6.8.14 Propagation delay</section-head>
          <section-head level="1">6.9 Graphical design entry</section-head>
          <section-head level="2">6.9.1 State machines</section-head>
          <section-head level="2">6.9.2 A more complex design</section-head>
          <section-head level="1">6.10 Applying our design method</section-head>
          <fpage>173</fpage>
          <lpage>230</lpage>
          <numpages>58</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>In this chapter we introduced the techniques used to design prototype intelligent sensor, starting with an overview of FPGA design, working through the VHDL language and showing how FPGA design can be simplified using graphical design entry tools. Given this background the discussion now moves on to consider the overall design of our prototype intelligent sensor by focusing on how data flows through the design; the implementation details are left to the appendices.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">A0670D</compound-classification-code-part><compound-classification-code-part type="text">Sensing and detecting devices</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">computer graphic equipment</keyword>
            <keyword source="Inspec">field programmable gate arrays</keyword>
            <keyword source="Inspec">hardware description languages</keyword>
            <keyword source="Inspec">intelligent sensors</keyword>
            <keyword source="Inspec">logic design</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">intelligent sensor design</keyword>
            <keyword source="uncontrolled">digital design method</keyword>
            <keyword source="uncontrolled">FPGA design</keyword>
            <keyword source="uncontrolled">VHDL</keyword>
            <keyword source="uncontrolled">graphical design entry tool</keyword>
            <keyword source="uncontrolled">data flow</keyword>
            <keyword source="uncontrolled">field programmable gate arrays</keyword>
            <keyword source="uncontrolled">very high speed integrated circuit hardware description language</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE067E_ch7</content-item-id>
          <doi>10.1049/PBCE067E_ch7</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Sensor implementation</title>
          <search-title>Sensor implementation</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>chapter</content-item-type>
          <bookseq>8</bookseq>
          <item-num>7</item-num>
          <supertitle1>Part3: Hardware</supertitle1>
          <section-head level="1">7.1 Components</section-head>
          <section-head level="2">7.1.1 Image sensor</section-head>
          <section-head level="2">7.1.2 Range sensor</section-head>
          <section-head level="2">7.1.3 processing platform</section-head>
          <section-head level="2">7.1.4 PC</section-head>
          <section-head level="1">7.2 FPGA system design</section-head>
          <section-head level="2">7.2.1 Boot process</section-head>
          <section-head level="2">7.2.2 Order of operations</section-head>
          <section-head level="2">7.2.3 Memory management</section-head>
          <section-head level="2">7.2.4 RAMIC</section-head>
          <section-head level="2">7.2.5 Buffers</section-head>
          <section-head level="2">7.2.6 Data paths</section-head>
          <section-head level="1">7.3 Experimental results</section-head>
          <section-head level="2">7.3.1 Experimental setup</section-head>
          <section-head level="2">7.3.2 Aligning the camera and range sensors</section-head>
          <section-head level="2">7.3.3 Stationary camera</section-head>
          <section-head level="2">7.3.4 Moving camera - effect of barrel distortion</section-head>
          <section-head level="2">7.3.5 Moving camera - elimination of barrel distortion</section-head>
          <section-head level="2">7.3.6 Moving camera - image noise</section-head>
          <section-head level="2">7.3.7 Moving camera - noise motion and high velocities</section-head>
          <section-head level="1">7.4 Implementation statistics</section-head>
          <section-head level="1">7.5 Where to from here?</section-head>
          <section-head level="2">7.5.1 Dynamic scale space</section-head>
          <section-head level="2">7.5.2 Extending the LTSV estimator</section-head>
          <section-head level="2">7.5.3 Temporal integration</section-head>
          <section-head level="2">7.5.4 Trimming versus Winsorising</section-head>
          <section-head level="2">7.5.5 Rough ground</section-head>
          <section-head level="2">7.5.6 Extending the hardware</section-head>
          <fpage>231</fpage>
          <lpage>282</lpage>
          <numpages>52</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>This chapter discusses the sensor implementation. Developing an appropriate motion estimation algorithm is only the first part of creating a practical intelligent motion sensor for use in autonomous navigation. Once the algorithm is verified and its operational parameters defined, it must be implemented so that those parameters are met. The algorithm developed in this book is relatively simple, so implementation using modern, general purpose processing hard ware such as the humble PC is feasible. Use of a PC would also simplify development and testing thanks to the large and mature set of development tools available.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">A0670D</compound-classification-code-part><compound-classification-code-part type="text">Sensing and detecting devices</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">intelligent sensors</keyword>
            <keyword source="Inspec">motion estimation</keyword>
            <keyword source="Inspec">navigation</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">sensor implementation</keyword>
            <keyword source="uncontrolled">motion estimation algorithm</keyword>
            <keyword source="uncontrolled">intelligent motion sensor</keyword>
            <keyword source="uncontrolled">autonomous navigation</keyword>
            <keyword source="uncontrolled">general purpose processing hardware</keyword>
            <keyword source="uncontrolled">development tool</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE067E_appendixa</content-item-id>
          <doi>10.1049/PBCE067E_appendixa</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Appendix A: System timing</title>
          <search-title>Appendix A: System timing</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>appendix</content-item-type>
          <bookseq>9</bookseq>
          <supertitle1>Part4: Appendices</supertitle1>
          <section-head level="1">A.1 Timing for a 512 &#x00D7; 32 pixel image</section-head>
          <section-head level="1">A.2 Control flow for a 512 &#x00D7; 32 pixel image</section-head>
          <section-head level="1">A.3 Timing for a 32 &#x00D7; 32 pixel image</section-head>
          <section-head level="1">A.4 Control flow for a 32 &#x00D7; 32 pixel image</section-head>
          <section-head level="1">A.5 Legend for timing diagrams</section-head>
          <section-head level="2">A.5.1 Note 1: image data clobbering</section-head>
          <section-head level="2">A.5.2 Note 2: the use of n in the timing diagram</section-head>
          <section-head level="2">A.5.3 Note 3: scale space change over process</section-head>
          <section-head level="2">A.5.4 Note 4: the first frame</section-head>
          <fpage>285</fpage>
          <lpage>296</lpage>
          <numpages>12</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>This appendix gives details of our sensor's internal timing and control flow. For illustrative purposes we show the tuning and control flow for both a 512x32 pixel image (re. the case where there is no subsampling due to scale space) and a 32x32 pixel image (where there is maximal subsampling). After the tuning diagrams there is a table detailing the meaning of labels in the diagrams. Note that all diagrams assume 10 Hz operation for the sensor. At higher rates only the inter-frame tune changes the tuning for individual data elements remains the same.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">A4280Q</compound-classification-code-part><compound-classification-code-part type="text">Image detectors, convertors, and intensifiers</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">image sampling</keyword>
            <keyword source="Inspec">image sensors</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">sensor</keyword>
            <keyword source="uncontrolled">control flow</keyword>
            <keyword source="uncontrolled">timing flow</keyword>
            <keyword source="uncontrolled">pixel image</keyword>
            <keyword source="uncontrolled">interframe time</keyword>
            <keyword source="uncontrolled">system timing</keyword>
            <keyword source="uncontrolled">subsampling</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE067E_appendixb</content-item-id>
          <doi>10.1049/PBCE067E_appendixb</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Appendix B: SDRAM timing</title>
          <search-title>Appendix B: SDRAM timing</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>appendix</content-item-type>
          <bookseq>10</bookseq>
          <supertitle1>Part4: Appendices</supertitle1>
          <section-head level="1">B.1 Powerup sequence</section-head>
          <section-head level="1">B.2 Read cycle</section-head>
          <section-head level="1">B.3 Write cycle</section-head>
          <fpage>297</fpage>
          <lpage>300</lpage>
          <numpages>4</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>Our design makes use of the SDRAM<emph type="superior">241</emph> available on the Gatesmaster/SignalMaster board used in this work. This appendix details the tuning used to access that memory. This appendix is not intended as a tutorial on the use of SDRAM (see Reference 274 for a useful introduction) but rather to clarify the timing used in the design of our FPGA. We access SDRAM using single word bursts and a CAS latency of 2.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">B1265D</compound-classification-code-part><compound-classification-code-part type="text">Memory circuits</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">DRAM chips</keyword>
            <keyword source="Inspec">field programmable gate arrays</keyword>
            <keyword source="Inspec">timing circuits</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">SDRAM timing</keyword>
            <keyword source="uncontrolled">gatesmaster-signalmaster board</keyword>
            <keyword source="uncontrolled">memory access</keyword>
            <keyword source="uncontrolled">FPGA</keyword>
            <keyword source="uncontrolled">single word burst</keyword>
            <keyword source="uncontrolled">CAS latency</keyword>
          </keywords>
        </vocabs>
        <funding-grp><access type="free"/></funding-grp>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE067E_appendixc</content-item-id>
          <doi>10.1049/PBCE067E_appendixc</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Appendix C: FPGA design</title>
          <search-title>Appendix C: FPGA design</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>appendix</content-item-type>
          <bookseq>11</bookseq>
          <supertitle1>Part4: Appendices</supertitle1>
          <section-head level="1">C.1 Summary of design components</section-head>
          <section-head level="1">C.2 Top level schematic</section-head>
          <section-head level="1">C.3 RAMIC</section-head>
          <section-head level="1">C.4 Buffers</section-head>
          <section-head level="2">C.4.1 Camera data path</section-head>
          <section-head level="1">C.5 Laser and PC data paths</section-head>
          <section-head level="1">C.6 processing</section-head>
          <section-head level="1">C.7 Miscellaneous components</section-head>
          <section-head level="1">C.8 User constraints file</section-head>
          <fpage>301</fpage>
          <lpage>376</lpage>
          <numpages>76</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>This chapter includes all design files (schematics, state machines and constraint files, all summarised in Section C. 1) for the FPGA based component of our design. Please remember that this is one of the first prototype designs, so while the design works, it should not be considered to be the 'best possible' implementation. No floor planning (beyond specifying which I/O pins to use) was performed in this design the final FPGA layout is entirely the result of automated tools. This implementation is targeted to the Xilinx Virtex XCV800 BG432 FPGA, and in particular, to the GatesMaster BITSI daughterboard (manufactured by Lyr Signal Processing [143]) using this FPGA. Naturally, this design will reflect the particular hardware we have used, particularly for I/O blocks, however, our design is quite modular so you should easily be able to modify the design to work with your hardware.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">B1265B</compound-classification-code-part><compound-classification-code-part type="text">Logic circuits</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">field programmable gate arrays</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">FPGA design</keyword>
            <keyword source="uncontrolled">Xilinx Virtex</keyword>
            <keyword source="uncontrolled">I/O block</keyword>
            <keyword source="uncontrolled">state machine</keyword>
            <keyword source="uncontrolled">constraint file</keyword>
            <keyword source="uncontrolled">schematics</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE067E_appendixd</content-item-id>
          <doi>10.1049/PBCE067E_appendixd</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Appendix D: Simulation of range data</title>
          <search-title>Appendix D: Simulation of range data</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>appendix</content-item-type>
          <bookseq>12</bookseq>
          <supertitle1>Part4: Appendices</supertitle1>
          <fpage>377</fpage>
          <lpage>394</lpage>
          <numpages>18</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>In this appendix we present the code we used to simulate range data. This is essentially a ray-tracing program where the user can specify a simple environment This is C code targeted at the ADSP Share 21062 DSP on the SignalMaster prototype platform used in our work and the code uses libraries targeted at this design environment Despite this, the core algorithm should be portable to any C compiler Please remember this is 'prototype code' it worked for our purposes but it is not necessarily fully documented and it may not represent an 'ideal' implementation. Use of this code (or any part thereof) is entirely at your risk. We cannot provide support and will not accept any liability for your use of this code (in part or whole). This code (or any part thereof) must not be used to maintain the safety or security of people or equipment.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">C6140D</compound-classification-code-part><compound-classification-code-part type="text">High level languages</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">C language</keyword>
            <keyword source="Inspec">program compilers</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">data simulation</keyword>
            <keyword source="uncontrolled">ray tracing program</keyword>
            <keyword source="uncontrolled">C code</keyword>
            <keyword source="uncontrolled">ADSP</keyword>
            <keyword source="uncontrolled">DSP</keyword>
            <keyword source="uncontrolled">libraries</keyword>
            <keyword source="uncontrolled">C compiler</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE067E_backmatter</content-item-id>
          <doi>10.1049/PBCE067E_bm</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Back Matter</title>
          <search-title>Back Matter</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>back matter</content-item-type>
          <bookseq>13</bookseq>
          <section-head level="1">Bibliography</section-head>
          <section-head level="1">Index</section-head>
          <fpage>395</fpage>
        </content-item-pubinfo>
        <funding-grp><access type="free"/></funding-grp>
      </content-item-metadata>
    </content-item>
  </body>
</ebook>
