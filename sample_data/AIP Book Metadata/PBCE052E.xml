<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE ebook PUBLIC "-//AIP//DTD XML Book Setup Module 1.0//EN" "AIPbookxml1.dtd">
<ebook xmlns:m="http://www.w3.org/1998/Math/MathML">
  <book-metadata>
    <book-identifiers>
      <bookid>PBCE052E</bookid>
      <doi>10.1049/PBCE052E</doi>
      <isbn13>9780863411939</isbn13>
      <isbn-eb>9781849193481</isbn-eb>
      <customerid>
        <identifier-name>IET</identifier-name>
        <identifier-value>PBCE0520</identifier-value>
      </customerid>
      <iet-subs>CE</iet-subs>
    </book-identifiers>
    <titlegrp>
      <title>Adaptive Prediction and Predictive Control</title>
      <search-title>Adaptive Prediction and Predictive Control</search-title>
    </titlegrp>
    <pubinfo>
      <numpages>536</numpages>
      <publication-date day="01" month="01" year="1995"></publication-date>
      <publisher-group>
        <ownerid>IET</ownerid>
        <publisher>Institution of Engineering and Technology</publisher>
      </publisher-group>
      <cpyrt>
        <cpyrtdate date="1995"/>
        <cpyrtholder>Institution of Engineering and Technology</cpyrtholder>
        <cpyrtstmt>All rights reserved. No part of this publication may be reproduced or distributed in any form or by any means without written permission of the  publisher</cpyrtstmt>
      </cpyrt>
      <price-model type="book-chapter"/>
    </pubinfo>
    <authgrp>
      <author>
        <fname>P.</fname><middlename>P.</middlename><surname>Kanjilal</surname>
        <fullname>P. P. Kanjilal</fullname>
      </author>
    </authgrp>
    <pubdesc>
      <p>This book is about prediction and control of processes which can be expressed by discrete-time models (i.e. the characteristics vary in some way with time). The aim of the book is to provide a unified and comprehensive coverage of the principles, perspectives and methods of adaptive prediction, which is used by scientists and researchers in a wide variety of disciplines.</p>
    </pubdesc>
    <abstract>
      <p>The book reviews developments in the following fields: process models; parameter estimation; adaptive prediction; transfer-function models; Kalman filter; state-space approaches; periodic series; nonlinear processes; GMDH; neural networks; quasiperiodic series; predictive control; input-output model; and smoothing and filtering.</p>
    </abstract>
    <vocabs>
      <classification-codes source="Inspec-class">
        <compound-classification-code><compound-classification-code-part type="code">C1300</compound-classification-code-part><compound-classification-code-part type="text">Control theory</compound-classification-code-part></compound-classification-code>
      </classification-codes>
      <keywords source="Inspec">
        <keyword source="Inspec">adaptive control</keyword>
        <keyword source="Inspec">Kalman filters</keyword>
        <keyword source="Inspec">neurocontrollers</keyword>
        <keyword source="Inspec">nonlinear control systems</keyword>
        <keyword source="Inspec">parameter estimation</keyword>
        <keyword source="Inspec">predictive control</keyword>
        <keyword source="Inspec">state-space methods</keyword>
        <keyword source="Inspec">transfer functions</keyword>
      </keywords>
      <keywords source="uncontrolled">
        <keyword source="uncontrolled">adaptive prediction</keyword>
        <keyword source="uncontrolled">predictive control</keyword>
        <keyword source="uncontrolled">process models</keyword>
        <keyword source="uncontrolled">parameter estimation</keyword>
        <keyword source="uncontrolled">transfer-function models</keyword>
        <keyword source="uncontrolled">Kalman filter</keyword>
        <keyword source="uncontrolled">state-space approaches</keyword>
        <keyword source="uncontrolled">nonlinear processes</keyword>
        <keyword source="uncontrolled">GMDH</keyword>
        <keyword source="uncontrolled">neural networks</keyword>
        <keyword source="uncontrolled">quasiperiodic series</keyword>
        <keyword source="uncontrolled">input-output model</keyword>
        <keyword source="uncontrolled">smoothing</keyword>
      </keywords>
      <tia>adaptive control, Kalman filters, neurocontrollers, nonlinear control systems, parameter estimation, predictive control, state-space methods, transfer functions</tia>
      <booktype>Control Engineering</booktype>
    </vocabs>
  </book-metadata>
  <body>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_frontmatter</content-item-id>
          <doi>10.1049/PBCE052E_fm</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Front Matter</title>
          <search-title>Front Matter</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>front matter</content-item-type>
          <bookseq>1</bookseq>
          <section-head level="1">Preface</section-head>
        </content-item-pubinfo>
        <funding-grp><access type="free"/></funding-grp>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_ch1</content-item-id>
          <doi>10.1049/PBCE052E_ch1</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Introduction</title>
          <search-title>Introduction</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>chapter</content-item-type>
          <bookseq>2</bookseq>
          <item-num>1</item-num>
          <fpage>1</fpage>
          <lpage>8</lpage>
          <numpages>8</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>Meaningful predictions, control based on predictive performance, and robust implementation are the main themes of this book.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">C1330</compound-classification-code-part><compound-classification-code-part type="text">Optimal control</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">adaptive control</keyword>
            <keyword source="Inspec">prediction theory</keyword>
            <keyword source="Inspec">predictive control</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">adaptive prediction</keyword>
            <keyword source="uncontrolled">predictive control</keyword>
            <keyword source="uncontrolled">predictive performance</keyword>
            <keyword source="uncontrolled">robust implementation</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_ch2</content-item-id>
          <doi>10.1049/PBCE052E_ch2</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Process models</title>
          <search-title>Process models</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>chapter</content-item-type>
          <bookseq>3</bookseq>
          <item-num>2</item-num>
          <section-head level="1">2.1 Introduction</section-head>
          <section-head level="1">2.2 process Models and their Choice</section-head>
          <section-head level="2">2.2.1 Classes of models</section-head>
          <section-head level="2">2.2.2 Choice of models</section-head>
          <section-head level="1">2.3 Stochastic processes</section-head>
          <section-head level="2">2.3.1 Basic concepts and processes</section-head>
          <section-head level="2">2.3.2 Examples of common processes</section-head>
          <section-head level="1">2.4 Transfer-function Models</section-head>
          <section-head level="2">2.4.1 Some basic models</section-head>
          <section-head level="2">2.4.2 Model structures</section-head>
          <section-head level="2">2.4.3 Other models</section-head>
          <section-head level="1">2.5 Models Based On Frequency Domain Analysis</section-head>
          <section-head level="2">2.5.1 Representation of a periodic signal and the Fourier series</section-head>
          <section-head level="2">2.5.2 Representation of a nonperiodic signal and the Fourier transform</section-head>
          <section-head level="2">2.5.3 Discrete-time signals and their Fourier transform</section-head>
          <section-head level="2">2.5.4 Modelling of a periodic signal</section-head>
          <section-head level="1">2.6 Structural Modelling</section-head>
          <section-head level="2">2.6.1 A basic model</section-head>
          <section-head level="2">2.6.2 Models with multiple periodic components</section-head>
          <section-head level="1">2.7 Concluding Remarks</section-head>
          <section-head level="1">References</section-head>
          <fpage>9</fpage>
          <lpage>55</lpage>
          <numpages>47</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>Modelling concerns the mathematical representation of the nature of the process with respect to its environment; the purpose of modelling and the type of data available are important considerations.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">C1220</compound-classification-code-part><compound-classification-code-part type="text">Simulation, modelling and identification</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">modelling</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">process model</keyword>
            <keyword source="uncontrolled">modelling</keyword>
            <keyword source="uncontrolled">mathematical representation</keyword>
            <keyword source="uncontrolled">model design</keyword>
            <keyword source="uncontrolled">model structure</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_ch3</content-item-id>
          <doi>10.1049/PBCE052E_ch3</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Parameter Estimation</title>
          <search-title>Parameter Estimation</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>chapter</content-item-type>
          <bookseq>4</bookseq>
          <item-num>3</item-num>
          <section-head level="1">3.1 Introduction</section-head>
          <section-head level="1">3.2 Linear Regression and the Least Squares Method</section-head>
          <section-head level="2">3.2.1 Formulation of LS estimator</section-head>
          <section-head level="2">3.2.2 Features and properties</section-head>
          <section-head level="1">3.3 LS Estimation: Computational Aspects</section-head>
          <section-head level="2">3.3.1 Solving normal equations</section-head>
          <section-head level="2">3.3.2 Orthogonal LS estimation</section-head>
          <section-head level="2">3.3.3 Rank deficient LS estimation</section-head>
          <section-head level="2">3.3.4 Estimation with orthogonalized regressors</section-head>
          <section-head level="1">3.4 Recursive Least Squares Method</section-head>
          <section-head level="2">3.4.1 RLS formulation</section-head>
          <section-head level="2">3.4.2 Implementation aspects</section-head>
          <section-head level="1">3.5 Some Selected Methods: An Introduction</section-head>
          <section-head level="2">3.5.1 Instrumental variable method</section-head>
          <section-head level="2">3.5.2 Maximum likelihood method</section-head>
          <section-head level="2">3.5.3 The Koopmans-Levin method: implemented using SVD</section-head>
          <section-head level="1">3.6 Model Selection and Validation</section-head>
          <section-head level="2">3.6.1 Akaike information criterion (AIC)</section-head>
          <section-head level="2">3.6.2 Subset selection from an information set</section-head>
          <section-head level="2">3.6.3 Case study: Best subset-AR modelling using information criterion and subset selection</section-head>
          <section-head level="2">3.6.4 Linear Regression through subset selection</section-head>
          <section-head level="2">3.6.5 Cross validation</section-head>
          <section-head level="1">3.7 Conclusions</section-head>
          <section-head level="1">References</section-head>
          <fpage>56</fpage>
          <lpage>110</lpage>
          <numpages>55</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>System identification is a prerequisite to adaptive prediction and control; it concerns the generation (for example through specific experimentation) and collection of information, revealing the characteristic behaviour of the process, and development of a mathematical representation of the process. Thus while parameter estimation concerns the determination of the numerical values of the parameters of the process model which best describe the dynamics of the process, identification involves model structure selection, collection of relevant information, parameter estimation, and model validation. The nature of the model is very much process and problem dependent, as discussed in Chapter 2. This chapter is primarily devoted to the problem of parameter estimation, model order selection and validation.There are different methods of parameter estimation. The suitability of a method depends on the quality of information contained in the data, the conceptual model structure and the application concerned. A detailed study of the estimation methods is beyond the scope of this book. The discussions are focused mainly on the least squares (LS) method, which is a basic method for parameter estimation.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">C1220</compound-classification-code-part><compound-classification-code-part type="text">Simulation, modelling and identification</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">least mean squares methods</keyword>
            <keyword source="Inspec">parameter estimation</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">parameter estimation</keyword>
            <keyword source="uncontrolled">system identification</keyword>
            <keyword source="uncontrolled">model order selection</keyword>
            <keyword source="uncontrolled">model order validation</keyword>
            <keyword source="uncontrolled">conceptual model structure</keyword>
            <keyword source="uncontrolled">least squares method</keyword>
            <keyword source="uncontrolled">LS method</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_ch4</content-item-id>
          <doi>10.1049/PBCE052E_ch4</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Some popular methods of prediction</title>
          <search-title>Some popular methods of prediction</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>chapter</content-item-type>
          <bookseq>5</bookseq>
          <item-num>4</item-num>
          <section-head level="1">4.1 Introduction</section-head>
          <section-head level="1">4.2 Smoothing Methods of Prediction</section-head>
          <section-head level="2">4.2.1 Basic smoothing methods</section-head>
          <section-head level="2">4.2.2 Multiple smoothing algorithms</section-head>
          <section-head level="1">4.3 Box and Jenkins Method</section-head>
          <section-head level="2">4.3.1 Modelling characteristics</section-head>
          <section-head level="2">4.3.2 Implementation aspects</section-head>
          <section-head level="1">4.4 Other Selected Methods</section-head>
          <section-head level="1">4.5 Concluding Remarks</section-head>
          <section-head level="1">References</section-head>
          <fpage>111</fpage>
          <lpage>132</lpage>
          <numpages>22</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>The following sections are included: introduction; smoothing methods of prediction; box and Jenkins method; other selected methods; and concluding remarks.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">C1330</compound-classification-code-part><compound-classification-code-part type="text">Optimal control</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">predictive control</keyword>
            <keyword source="Inspec">smoothing methods</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">adaptive prediction</keyword>
            <keyword source="uncontrolled">predictive control</keyword>
            <keyword source="uncontrolled">smoothing method</keyword>
            <keyword source="uncontrolled">box method</keyword>
            <keyword source="uncontrolled">Jenkins method</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_ch5</content-item-id>
          <doi>10.1049/PBCE052E_ch5</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Adaptive prediction using transfer-function models</title>
          <search-title>Adaptive prediction using transfer-function models</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>chapter</content-item-type>
          <bookseq>6</bookseq>
          <item-num>5</item-num>
          <section-head level="1">5.1 Introduction</section-head>
          <section-head level="1">5.2 Minimum Mean Square Error Prediction</section-head>
          <section-head level="2">5.2.1 Explicit (indirect) prediction</section-head>
          <section-head level="2">5.2.2 Implicit (direct) prediction</section-head>
          <section-head level="1">5.3 Constrained Mean Square Error Prediction</section-head>
          <section-head level="2">5.3.1 Why constrain prediction</section-head>
          <section-head level="2">5.3.2 Cost criteria</section-head>
          <section-head level="2">5.3.3 Prediction formulations</section-head>
          <section-head level="2">5.3.4 Comparative study</section-head>
          <section-head level="1">5.4 Multistep Prediction Through process Model Recursion</section-head>
          <section-head level="1">5.5 -Case Study: Prediction of Product Quality in Iron-ore Sintering process</section-head>
          <section-head level="2">5.5.1 process description and prediction problem</section-head>
          <section-head level="2">5.5.2 Data preparation</section-head>
          <section-head level="2">5.5.3 Prediction exercise</section-head>
          <section-head level="1">5.6 Conclusions</section-head>
          <section-head level="1">References</section-head>
          <fpage>133</fpage>
          <lpage>159</lpage>
          <numpages>27</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>Adaptive prediction is usually based on minimization of the mean square prediction error. The prediction involves a two stage procedure: (i) estimation of the parameters of an appropriate model of the time series or the process, and (ii) reconfiguration of the process model into a prediction model, and computation of prediction using the estimated parameters.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">A0260</compound-classification-code-part><compound-classification-code-part type="text">Numerical approximation and analysis</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">mean square error methods</keyword>
            <keyword source="Inspec">time series</keyword>
            <keyword source="Inspec">transfer functions</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">adaptive prediction</keyword>
            <keyword source="uncontrolled">transfer-function models</keyword>
            <keyword source="uncontrolled">mean square prediction error</keyword>
            <keyword source="uncontrolled">time series</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_ch6</content-item-id>
          <doi>10.1049/PBCE052E_ch6</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Kalman filter and state-space approaches</title>
          <search-title>Kalman filter and state-space approaches</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>chapter</content-item-type>
          <bookseq>7</bookseq>
          <item-num>6</item-num>
          <section-head level="1">6.1 Introduction</section-head>
          <section-head level="1">6.2 State-space Representation</section-head>
          <section-head level="1">6.3 State Equations from Difference Equation Models</section-head>
          <section-head level="2">6.3.1 processes without measurement noise</section-head>
          <section-head level="2">6.3.2 processes with noise</section-head>
          <section-head level="1">6.4 State-space Models for Periodic processes</section-head>
          <section-head level="2">6.4.1 Trend model</section-head>
          <section-head level="2">6.4.2 Periodic component model</section-head>
          <section-head level="2">6.4.3 Prediction problem formulation</section-head>
          <section-head level="1">6.5 Optimal State Estimation</section-head>
          <section-head level="1">6.6 The Kalman Filter</section-head>
          <section-head level="2">6.6.1 The estimation problem</section-head>
          <section-head level="2">6.6.2 Kalman filter equations</section-head>
          <section-head level="2">6.6.3 Properties and salient features</section-head>
          <section-head level="2">6.6.4 Implementation aspects</section-head>
          <section-head level="1">6.7 Optimal Prediction</section-head>
          <section-head level="1">6.8 Case Study: Estimation and Prediction of Ingot Temperatures and Heating in Soaking Pits</section-head>
          <section-head level="2">6.8.1 process description and problem statement</section-head>
          <section-head level="2">6.8.2 Modelling, estimation and prediction</section-head>
          <section-head level="1">6.9 Concluding Remarks</section-head>
          <section-head level="1">References</section-head>
          <fpage>160</fpage>
          <lpage>199</lpage>
          <numpages>40</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>In this chapter, state-space modelling and optimal estimation of states using the Kalman filter were studied. Compared with the transfer function models based on input-output data, the state-space approach offers the additional flexibility of accommodating internal variables as states, which may not be accessible or measurable. The state-space approach permits use of a large number of widely studied and well-established methods and algorithms for estimation, prediction, smoothing and control. The Kalman filter can produce optimal state estimates under steady state conditions, even when the measurements are noisy, conditional on the noise being independent with Gaussian distribution.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">C1310</compound-classification-code-part><compound-classification-code-part type="text">Control system analysis and synthesis methods</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">Gaussian distribution</keyword>
            <keyword source="Inspec">Kalman filters</keyword>
            <keyword source="Inspec">parameter estimation</keyword>
            <keyword source="Inspec">state-space methods</keyword>
            <keyword source="Inspec">transfer functions</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">state-space modelling</keyword>
            <keyword source="uncontrolled">states estimation</keyword>
            <keyword source="uncontrolled">Kalman filter</keyword>
            <keyword source="uncontrolled">transfer function models</keyword>
            <keyword source="uncontrolled">Gaussian distribution</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_ch7</content-item-id>
          <doi>10.1049/PBCE052E_ch7</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Orthogonal transformation and modelling of periodic series</title>
          <search-title>Orthogonal transformation and modelling of periodic series</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>chapter</content-item-type>
          <bookseq>8</bookseq>
          <item-num>7</item-num>
          <section-head level="1">7.1 Introduction</section-head>
          <section-head level="1">7.2 Basics of Orthogonal Transformation</section-head>
          <section-head level="1">7.3 Karhunen-Lodve Transformation</section-head>
          <section-head level="1">7.4 Walsh-Hadamard Transform</section-head>
          <section-head level="2">7.4.1 Generation of Walsh functions using Hadamard matrices</section-head>
          <section-head level="2">7.4.2 One-dimensional WHT</section-head>
          <section-head level="2">7.4.3 Two-dimensional WHT</section-head>
          <section-head level="1">7.5 Prediction based on WHT</section-head>
          <section-head level="2">7.5.1 Basic principle</section-head>
          <section-head level="2">7.5.2 Prediction of power load on a substation</section-head>
          <section-head level="1">7.6 Singular Value Decomposition (SVD)</section-head>
          <section-head level="2">7.6.1 Introduction to singular value decomposition</section-head>
          <section-head level="2">7.6.2 Characteristic features of SVD</section-head>
          <section-head level="1">7.7 Characterization of Periodic processes using SVD</section-head>
          <section-head level="1">7.8 Modelling and Prediction using SVD</section-head>
          <section-head level="2">7.8.1 Principle of modelling</section-head>
          <section-head level="2">7.8.2 Case study: periodic prediction of airline traffic</section-head>
          <section-head level="1">7.9 Conclusions</section-head>
          <section-head level="1">References</section-head>
          <fpage>200</fpage>
          <lpage>235</lpage>
          <numpages>36</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>Two basic consequences of orthogonal transformation are relative decorrelation of data and compression of information, which can be used for modelling and prediction of periodic series.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">C6130</compound-classification-code-part><compound-classification-code-part type="text">Data handling techniques</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">data compression</keyword>
            <keyword source="Inspec">Hadamard transforms</keyword>
            <keyword source="Inspec">singular value decomposition</keyword>
            <keyword source="Inspec">Walsh functions</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">orthogonal transformation</keyword>
            <keyword source="uncontrolled">periodic series</keyword>
            <keyword source="uncontrolled">adaptive prediction</keyword>
            <keyword source="uncontrolled">predictive control</keyword>
            <keyword source="uncontrolled">data decorrelation</keyword>
            <keyword source="uncontrolled">information compression</keyword>
            <keyword source="uncontrolled">singular value decomposition</keyword>
            <keyword source="uncontrolled">Walsh-Hadamard transformation</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_ch8</content-item-id>
          <doi>10.1049/PBCE052E_ch8</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Modellong of nonlinear processes: an introduction</title>
          <search-title>Modellong of nonlinear processes: an introduction</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>chapter</content-item-type>
          <bookseq>9</bookseq>
          <item-num>8</item-num>
          <section-head level="1">8.1 Introduction</section-head>
          <section-head level="1">8.2 Basics of Nonlinear processes</section-head>
          <section-head level="2">8.2.1 Characteristic features</section-head>
          <section-head level="2">8.2.2 Basic models</section-head>
          <section-head level="2">8.2.3 Nonlinear transformation</section-head>
          <section-head level="1">8.3 Nonlinear Periodicity</section-head>
          <section-head level="2">8.3.1 Periodic, quasiperiodic and chaotic series</section-head>
          <section-head level="2">8.3.2 Analysis using state-space diagrams, SVD and FFT</section-head>
          <section-head level="1">8.4 Selected Nonlinear Models</section-head>
          <section-head level="2">8.4.1 Bilinear models</section-head>
          <section-head level="2">8.4.2 Threshold models</section-head>
          <section-head level="2">8.4.3 Exponential models</section-head>
          <section-head level="1">8.5 Conclusions</section-head>
          <section-head level="1">References</section-head>
          <fpage>236</fpage>
          <lpage>260</lpage>
          <numpages>25</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>Certain special features characterize a nonlinear process which can be represented by a single-stage or a multistage model, linear or nonlinear in the parameters.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">A0250</compound-classification-code-part><compound-classification-code-part type="text">Probability theory, stochastic processes, and statistics</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">time series</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">nonlinear processes</keyword>
            <keyword source="uncontrolled">multistage model</keyword>
            <keyword source="uncontrolled">single-stage model</keyword>
            <keyword source="uncontrolled">time series</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_ch9</content-item-id>
          <doi>10.1049/PBCE052E_ch9</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Modelling of nonlinear processes using GMDH</title>
          <search-title>Modelling of nonlinear processes using GMDH</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>chapter</content-item-type>
          <bookseq>10</bookseq>
          <item-num>9</item-num>
          <section-head level="1">9.1 Introduction</section-head>
          <section-head level="1">9.2 The GMDH Architecture</section-head>
          <section-head level="2">9.2.1 Multinomial representation of nonlinearity</section-head>
          <section-head level="2">9.2.2 Structural layout of GMDH</section-head>
          <section-head level="1">9.3 GMDH: Design and validation of models</section-head>
          <section-head level="1">9.4 Modelling The COD process In Osaka Bay</section-head>
          <section-head level="1">9.5 A Single Layer Nonlinear Model based on Orthogonal Transformation</section-head>
          <section-head level="1">9.6 Conclusions</section-head>
          <section-head level="1">References</section-head>
          <fpage>261</fpage>
          <lpage>273</lpage>
          <numpages>13</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>Nonlinear processes can be modelled using hierarchical stages of simple nonlinearity, where each building block is represented by a linear-in-the-parameter model.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">C1340K</compound-classification-code-part><compound-classification-code-part type="text">Nonlinear control systems</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">data handling</keyword>
            <keyword source="Inspec">hierarchical systems</keyword>
            <keyword source="Inspec">modelling</keyword>
            <keyword source="Inspec">nonlinear control systems</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">nonlinear processes</keyword>
            <keyword source="uncontrolled">modelling</keyword>
            <keyword source="uncontrolled">GMDH</keyword>
            <keyword source="uncontrolled">hierarchical stages</keyword>
            <keyword source="uncontrolled">simple nonlinearity</keyword>
            <keyword source="uncontrolled">linear-in-the-parameter model</keyword>
            <keyword source="uncontrolled">group method of data handling</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_ch10</content-item-id>
          <doi>10.1049/PBCE052E_ch10</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Modelling and prediction of nonlinear processesusing neural networks</title>
          <search-title>Modelling and prediction of nonlinear processesusing neural networks</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>chapter</content-item-type>
          <bookseq>11</bookseq>
          <item-num>10</item-num>
          <section-head level="1">10.1 Introduction</section-head>
          <section-head level="1">10.2 Basics of Neural Networks</section-head>
          <section-head level="1">10.3 Multilayer Perceptron and Backpropagation Algorithm</section-head>
          <section-head level="2">10.3.1 Backpropagation learning</section-head>
          <section-head level="2">10.3.2 Application Example</section-head>
          <section-head level="1">10.4 Design of Optimum Networks Using SVD and Subset Selection</section-head>
          <section-head level="2">10.4.1 Determination of optimum architecture</section-head>
          <section-head level="2">10.4.2 Modelling and prediction of Mackey-Glass series</section-head>
          <section-head level="2">10.4.3 Modelling of chemical oxygen demand (COD) in Osaka Bay</section-head>
          <section-head level="1">10.5 Modelling Networks with Orthogonalized Data</section-head>
          <section-head level="2">10.5.1 Modelling principle and perspective</section-head>
          <section-head level="2">10.5.2 Modelling of the Indian rainfall series</section-head>
          <section-head level="1">10.6 Assessment of Convergence using SVD</section-head>
          <section-head level="1">10.7 Conclusions</section-head>
          <section-head level="1">References</section-head>
          <fpage>274</fpage>
          <lpage>303</lpage>
          <numpages>30</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>Nonlinear series with or without periodicity as well as nonlinear input-output processes can be modelled using neural networks.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">C1220</compound-classification-code-part><compound-classification-code-part type="text">Simulation, modelling and identification</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">modelling</keyword>
            <keyword source="Inspec">neural nets</keyword>
            <keyword source="Inspec">nonlinear systems</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">nonlinear processes prediction</keyword>
            <keyword source="uncontrolled">nonlinear processes modelling</keyword>
            <keyword source="uncontrolled">neural networks</keyword>
            <keyword source="uncontrolled">nonlinear series</keyword>
            <keyword source="uncontrolled">nonlinear input-output processes</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_ch11</content-item-id>
          <doi>10.1049/PBCE052E_ch11</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Modelling and prediction of quasiperiodic series</title>
          <search-title>Modelling and prediction of quasiperiodic series</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>chapter</content-item-type>
          <bookseq>12</bookseq>
          <item-num>11</item-num>
          <section-head level="1">11.1 Introduction</section-head>
          <section-head level="1">11.2 Modelling using SVD and Nonlinear Transformation</section-head>
          <section-head level="2">11.2.1 Data preparation</section-head>
          <section-head level="2">11.2.2 Modelling and prediction</section-head>
          <section-head level="2">11.2.3 Application study using the sunspot series</section-head>
          <section-head level="1">11.3 Modelling using SVD and Neural Network</section-head>
          <section-head level="1">11.4 Modelling of Quasiperiodic Series through Periodic Decomposition</section-head>
          <section-head level="2">11.4.1 Introduction to periodic decomposition</section-head>
          <section-head level="2">11.4.2 Period length estimation for periodic components</section-head>
          <section-head level="2">11.4.3 Estimation of the strongest periodic component</section-head>
          <section-head level="2">11.4.4 Implementation considerations</section-head>
          <section-head level="2">11.4.5 Application examples</section-head>
          <section-head level="1">11.5 Conclusions</section-head>
          <section-head level="1">References</section-head>
          <fpage>304</fpage>
          <lpage>330</lpage>
          <numpages>27</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>Modelling of nearly periodic time series is quite straight forward and can be done for example using the singular value decomposition based method or using Box and Jenkins method. So if a quasiperiodic series can be configured into multiple nearly periodic series through decomposition or transformation, the modelling problem can be simplified; this is the basic concept used for modelling quasiperiodic series in this chapter.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">A0250</compound-classification-code-part><compound-classification-code-part type="text">Probability theory, stochastic processes, and statistics</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">singular value decomposition</keyword>
            <keyword source="Inspec">time series</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">quasiperiodic series</keyword>
            <keyword source="uncontrolled">nearly periodic time series</keyword>
            <keyword source="uncontrolled">singular value decomposition</keyword>
            <keyword source="uncontrolled">Box and Jenkins method</keyword>
            <keyword source="uncontrolled">multiple nearly periodic series</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_ch12</content-item-id>
          <doi>10.1049/PBCE052E_ch12</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Predictive control (Part-I): input-output model based</title>
          <search-title>Predictive control (Part-I): input-output model based</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>chapter</content-item-type>
          <bookseq>13</bookseq>
          <item-num>12</item-num>
          <section-head level="1">12.1 Introduction</section-head>
          <section-head level="1">12.2 Self-Tuning Control</section-head>
          <section-head level="2">12.2.1 Basic concepts</section-head>
          <section-head level="2">12.2.2 Control algorithms</section-head>
          <section-head level="2">12.2.3 Controller as operator-guide: an example</section-head>
          <section-head level="1">12.3 Long Range Predictive Control</section-head>
          <section-head level="2">12.3.1 Introduction</section-head>
          <section-head level="2">12.3.2 The generic structure</section-head>
          <section-head level="1">12.4 LRPC: Pulse Response Model based</section-head>
          <section-head level="1">12.5 LRPC: Step Response Model based</section-head>
          <section-head level="1">12.6 Generalized Predictive Control</section-head>
          <section-head level="1">12.7 LRPC: Design Considerations</section-head>
          <section-head level="1">12.8 Implementation Aspects of LRPC</section-head>
          <section-head level="1">12.9 Conclusions</section-head>
          <section-head level="1">References</section-head>
          <fpage>331</fpage>
          <lpage>365</lpage>
          <numpages>35</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>Predictive control aims at obtaining the predicted performance of the process as specified. This chapter describes some of the popularly used predictive control methods for linear systems. A real-life process is usually dynamic in nature, and it works in a stochastic environment; so it is necessary for the controller to be adaptive.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">C1330</compound-classification-code-part><compound-classification-code-part type="text">Optimal control</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">adaptive control</keyword>
            <keyword source="Inspec">linear systems</keyword>
            <keyword source="Inspec">predictive control</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">predictive control</keyword>
            <keyword source="uncontrolled">input-output model</keyword>
            <keyword source="uncontrolled">predicted performance</keyword>
            <keyword source="uncontrolled">linear systems</keyword>
            <keyword source="uncontrolled">stochastic environment</keyword>
            <keyword source="uncontrolled">adaptive controller</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_ch13</content-item-id>
          <doi>10.1049/PBCE052E_ch13</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Predictive control (Part-II): state-space model based</title>
          <search-title>Predictive control (Part-II): state-space model based</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>chapter</content-item-type>
          <bookseq>14</bookseq>
          <item-num>13</item-num>
          <section-head level="1">13.1 Introduction</section-head>
          <section-head level="1">13.2 LQ Control of a Deterministic process</section-head>
          <section-head level="1">13.3 Separation Theorem and Control of a Stochastic process</section-head>
          <section-head level="2">13.3.1 The control problem</section-head>
          <section-head level="2">13.3.2 Separation theorem and controller synthesis</section-head>
          <section-head level="1">13.4 Duality Between LQ Control and State Estimator</section-head>
          <section-head level="1">13.5 LQ Control of Time Varying processes</section-head>
          <section-head level="2">13.5.1 process models</section-head>
          <section-head level="2">13.5.2 Cost functions</section-head>
          <section-head level="1">13.6 Estimation of the State ^x(k|k)</section-head>
          <section-head level="2">13.6.1 State estimation from CARMA model</section-head>
          <section-head level="2">13.6.2 State estimation from CARIMA model</section-head>
          <section-head level="1">13.7 Computation of Control</section-head>
          <section-head level="2">13.7.1 Control horizons</section-head>
          <section-head level="2">13.7.2 Implementation based on the principle of duality</section-head>
          <section-head level="2">13.7.3 Implementation aspects and features</section-head>
          <section-head level="2">13.7.4 Self-tuning control</section-head>
          <section-head level="1">13.8 Simulation Studies</section-head>
          <section-head level="1">13.9 Conclusions</section-head>
          <section-head level="1">References</section-head>
          <fpage>366</fpage>
          <lpage>398</lpage>
          <numpages>33</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>Long range predictive control (LRPC) methods formulated using transfer function models were discussed in Chapter 12. This chapter is devoted to the study of state-space formulation of linear quadratic (LQ) controllers, which form another popular class of predictive controllers. Here, the process is represented by a linear state-space model, and the cost criterion is a quadratic function of the states and the control inputs. If the disturbances to the process (as expressed by the model), are Gaussian in nature, the LQ control is referred to as the linear quadratic Gaussian (LQG) control.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">C1330</compound-classification-code-part><compound-classification-code-part type="text">Optimal control</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">Gaussian processes</keyword>
            <keyword source="Inspec">linear quadratic Gaussian control</keyword>
            <keyword source="Inspec">predictive control</keyword>
            <keyword source="Inspec">state-space methods</keyword>
            <keyword source="Inspec">transfer functions</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">long range predictive control</keyword>
            <keyword source="uncontrolled">transfer function models</keyword>
            <keyword source="uncontrolled">linear quadratic controllers</keyword>
            <keyword source="uncontrolled">linear state-space model</keyword>
            <keyword source="uncontrolled">cost criterion</keyword>
            <keyword source="uncontrolled">quadratic function</keyword>
            <keyword source="uncontrolled">linear quadratic Gaussian control</keyword>
            <keyword source="uncontrolled">LQG control</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_ch14</content-item-id>
          <doi>10.1049/PBCE052E_ch14</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Smoothing and filtering</title>
          <search-title>Smoothing and filtering</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>chapter</content-item-type>
          <bookseq>15</bookseq>
          <item-num>14</item-num>
          <section-head level="1">14.1 Introduction</section-head>
          <section-head level="1">14.2 Optimal State-Space Smoothing</section-head>
          <section-head level="2">14.2.1 Fixed-interval smoothing</section-head>
          <section-head level="2">14.2.2 Fixed-point smoothing</section-head>
          <section-head level="2">14.2.3 Fixed-lag smoothing</section-head>
          <section-head level="2">14.2.4 Observations and comparative study</section-head>
          <section-head level="1">14.3 Bidirectional Filtering</section-head>
          <section-head level="2">14.3.1 Off-line method</section-head>
          <section-head level="2">14.3.2 Real-time filtering</section-head>
          <section-head level="1">14.4 Smoothing and Filtering using Orthogonal Transformation</section-head>
          <section-head level="1">14.5 Smoothing and Filtering using SVD</section-head>
          <section-head level="2">14.5.1 Smoothing</section-head>
          <section-head level="2">14.5.2 Pattern estimation</section-head>
          <section-head level="2">14.5.3 Selective filtering</section-head>
          <section-head level="2">14.5.4 Case study: Fetal ECG extraction from maternal ECG</section-head>
          <section-head level="1">14.6 Conclusions</section-head>
          <section-head level="1">References</section-head>
          <fpage>399</fpage>
          <lpage>430</lpage>
          <numpages>32</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>Some methods for separation or extraction of usable information from the available data have been presented. First, optimum smoothing in state-space framework was discussed, which was to familiarize the reader with the various issues connected with smoothing. This was followed by studies on bidirectional filtering, which can be used to perform smoothing with minimum lag or phase shift. The bidirectional processing is a characteristic feature which is incorporated in many algorithms for bias-free processing; for example the fixed interval smoother uses similar forward-backward passes, and the centred moving average used in the time series analysis is also effectively similar in concept. Orthogonal transformation offers a numerically robust method of smoothing and signal extraction. The smoothing is performed through the elimination of insignificant on singular value decomposition (SVD). Besides smoothing, the potential of the SVD based methods in signal extraction and pattern estimation in a noisy environment was also demonstrated through application studies. The approach depends on the repetitive nature of the signal component of interest, and hence the data are appropriately configured for analysis. A case study on fetal ECG extraction from maternal ECG showed that extraction is possible with only one signal (i.e. the maternal ECG signal from the abdominal lead), and irrespective of low signal to noise ratio; the other available methods of fetal ECG extraction require one or more additional signals. The application of orthogonal transformation for smoothing and filtering is an area of active research, and the present study has been only a glimpse of its enormous potential.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">B6140B</compound-classification-code-part><compound-classification-code-part type="text">Filtering methods in signal processing</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">feature extraction</keyword>
            <keyword source="Inspec">filtering theory</keyword>
            <keyword source="Inspec">signal denoising</keyword>
            <keyword source="Inspec">singular value decomposition</keyword>
            <keyword source="Inspec">smoothing methods</keyword>
            <keyword source="Inspec">time series</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">information separation</keyword>
            <keyword source="uncontrolled">information extraction</keyword>
            <keyword source="uncontrolled">state-space framework</keyword>
            <keyword source="uncontrolled">bidirectional filtering</keyword>
            <keyword source="uncontrolled">phase shift</keyword>
            <keyword source="uncontrolled">bidirectional processing</keyword>
            <keyword source="uncontrolled">feature characteristic</keyword>
            <keyword source="uncontrolled">bias-free processing</keyword>
            <keyword source="uncontrolled">fixed interval smoother</keyword>
            <keyword source="uncontrolled">time series analysis</keyword>
            <keyword source="uncontrolled">smoothing method</keyword>
            <keyword source="uncontrolled">signal extraction</keyword>
            <keyword source="uncontrolled">singular value decomposition</keyword>
            <keyword source="uncontrolled">SVD based method</keyword>
            <keyword source="uncontrolled">pattern estimation</keyword>
            <keyword source="uncontrolled">noisy environment</keyword>
            <keyword source="uncontrolled">signal component</keyword>
            <keyword source="uncontrolled">fetal ECG extraction</keyword>
            <keyword source="uncontrolled">signal to noise ratio</keyword>
            <keyword source="uncontrolled">orthogonal transformation</keyword>
            <keyword source="uncontrolled">filtering method</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_appendix1</content-item-id>
          <doi>10.1049/PBCE052E_appendix1</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Appendix 1: Vector and matrix operations</title>
          <search-title>Appendix 1: Vector and matrix operations</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>appendix</content-item-type>
          <bookseq>16</bookseq>
          <fpage>431</fpage>
          <lpage>438</lpage>
          <numpages>8</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>The following topics are dealt with: basic definitions; matrix multiplication; determinant; matrix inversion; and differentiation.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">A0130C</compound-classification-code-part><compound-classification-code-part type="text">Conference proceedings</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">differentiation</keyword>
            <keyword source="Inspec">matrix inversion</keyword>
            <keyword source="Inspec">vectors</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">vector operations</keyword>
            <keyword source="uncontrolled">matrix operations</keyword>
            <keyword source="uncontrolled">basic definitions</keyword>
            <keyword source="uncontrolled">matrix multiplication</keyword>
            <keyword source="uncontrolled">determinant</keyword>
            <keyword source="uncontrolled">matrix inversion</keyword>
            <keyword source="uncontrolled">differentiation</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_appendix2</content-item-id>
          <doi>10.1049/PBCE052E_appendix2</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Appendix 2: Exponential Fourier series</title>
          <search-title>Appendix 2: Exponential Fourier series</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>appendix</content-item-type>
          <bookseq>17</bookseq>
          <fpage>439</fpage>
          <lpage>440</lpage>
          <numpages>2</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>The trigonometric Fourier series representation of a periodic process f(t), with period T, was discussed in Sec.2.5.1. The derivation of exponential Fourier series representation is presented here. The sinusoidal functions can be expressed in terms of exponential functions as follows e = cos&#x03B8; + lsin&#x03B8;, l, i&#x03B8; -i&#x03B8;&#x039B; . 1, l&#x03B8; -l&#x03B8;v . f-r cos&#x03B8; = -(e + e ), sm&#x03B8; = -(e e ), i v-1. So the trigonometric Fourier series (2.5.2) can be expressed as f(t) = a&#x03BF; i &#x03A3;We&#x03B9;&#x03B7;&#x03C9;'Ve-&#x03B9;&#x03B7;&#x03C9;o1) ib&#x03B7;fe&#x03B9;&#x03B7;&#x03C9;o&#x03B9;-e&#x201C;1"^)).</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">A0210</compound-classification-code-part><compound-classification-code-part type="text">Algebra, set theory, and graph theory</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">exponential distribution</keyword>
            <keyword source="Inspec">Fourier series</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">exponential Fourier Series</keyword>
            <keyword source="uncontrolled">trigonometric Fourier series</keyword>
            <keyword source="uncontrolled">sinusoidal functions</keyword>
            <keyword source="uncontrolled">exponential functions</keyword>
          </keywords>
        </vocabs>
        <funding-grp><access type="free"/></funding-grp>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_appendix3</content-item-id>
          <doi>10.1049/PBCE052E_appendix3</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Appendix 3: U-D covariance measurement update</title>
          <search-title>Appendix 3: U-D covariance measurement update</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>appendix</content-item-type>
          <bookseq>18</bookseq>
          <fpage>441</fpage>
          <lpage>448</lpage>
          <numpages>8</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>In sequential state estimation, the covariance of the estimation error undergoes two different updates: (i) the measurement update, and (ii) the time update. The generic expressions for these two updates with respect to the Kalman filter state estimator are discussed in Sec.6.6. These updates appear in different areas of estimation and control.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">C1220</compound-classification-code-part><compound-classification-code-part type="text">Simulation, modelling and identification</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">covariance matrices</keyword>
            <keyword source="Inspec">Kalman filters</keyword>
            <keyword source="Inspec">state estimation</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">sequential state estimation</keyword>
            <keyword source="uncontrolled">covariance</keyword>
            <keyword source="uncontrolled">estimation error</keyword>
            <keyword source="uncontrolled">Kalman filter</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_appendix4</content-item-id>
          <doi>10.1049/PBCE052E_appendix4</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Appendix 4: Centred moving average</title>
          <search-title>Appendix 4: Centred moving average</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>appendix</content-item-type>
          <bookseq>19</bookseq>
          <fpage>449</fpage>
          <lpage>450</lpage>
          <numpages>2</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>The two basic purposes of Centred Moving Averaging (CMA) are (i) estimation of trend in a time series without any time-lag, and (ii) reduction of the effects of random or spurious noise associated with the data. The general consequence of averaging is low-pass filtering, that is the high frequency components are attenuated whereas the low frequency components are retained. Any averaging which uses present and the past data only will produce a time-lag in the averaged data. In CMA, since both past and post data are used, the lag-free estimate of the series is produced.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">B6140B</compound-classification-code-part><compound-classification-code-part type="text">Filtering methods in signal processing</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">low-pass filters</keyword>
            <keyword source="Inspec">moving average processes</keyword>
            <keyword source="Inspec">time series</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">centred moving average</keyword>
            <keyword source="uncontrolled">CMA</keyword>
            <keyword source="uncontrolled">time series</keyword>
            <keyword source="uncontrolled">low-pass filtering</keyword>
            <keyword source="uncontrolled">high frequency component</keyword>
            <keyword source="uncontrolled">low frequency component</keyword>
          </keywords>
        </vocabs>
        <funding-grp><access type="free"/></funding-grp>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_appendix5a</content-item-id>
          <doi>10.1049/PBCE052E_appendix5a</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Appendix 5A: Recursion of the Diophantine equation</title>
          <search-title>Appendix 5A: Recursion of the Diophantine equation</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>appendix</content-item-type>
          <bookseq>20</bookseq>
          <fpage>451</fpage>
          <lpage>453</lpage>
          <numpages>3</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>The following sections are included: problem statement; recursive solution; and implementation.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">A0250</compound-classification-code-part><compound-classification-code-part type="text">Probability theory, stochastic processes, and statistics</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">recursive estimation</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">recursion</keyword>
            <keyword source="uncontrolled">diophantine equation</keyword>
            <keyword source="uncontrolled">problem statement</keyword>
            <keyword source="uncontrolled">recursive solution</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_appendix5b</content-item-id>
          <doi>10.1049/PBCE052E_appendix5b</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Appendix 5B: Predictor for a multivariable process</title>
          <search-title>Appendix 5B: Predictor for a multivariable process</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>appendix</content-item-type>
          <bookseq>21</bookseq>
          <fpage>454</fpage>
          <lpage>455</lpage>
          <numpages>2</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>This section of the book deals with predictor algorithm formulated for multivariable stochastic process.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">C1340B</compound-classification-code-part><compound-classification-code-part type="text">Multivariable control systems</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">matrix algebra</keyword>
            <keyword source="Inspec">MIMO systems</keyword>
            <keyword source="Inspec">multivariable control systems</keyword>
            <keyword source="Inspec">stochastic processes</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">multivariable stochastic process</keyword>
            <keyword source="uncontrolled">predictor algorithm</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_appendix6</content-item-id>
          <doi>10.1049/PBCE052E_appendix6</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Appendix 6: The covariance matrix for P-step predictor</title>
          <search-title>Appendix 6: The covariance matrix for P-step predictor</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>appendix</content-item-type>
          <bookseq>22</bookseq>
          <fpage>456</fpage>
          <lpage>457</lpage>
          <numpages>2</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>The covariance matrix P(k+p|k) is indicative of the degree of confidence that the estimator has in x&#x0302;(k+p|k), the p-step ahead prediction of the state x(k). The derivation of P(k+p|k) is presented in this appendix.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">C1300</compound-classification-code-part><compound-classification-code-part type="text">Control theory</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">predictive control</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">P-step predictor</keyword>
            <keyword source="uncontrolled">covariance matrix</keyword>
          </keywords>
        </vocabs>
        <funding-grp><access type="free"/></funding-grp>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_appendix7a</content-item-id>
          <doi>10.1049/PBCE052E_appendix7a</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Appendix 7A: Details of selected examples of Chapter 7</title>
          <search-title>Appendix 7A: Details of selected examples of Chapter 7</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>appendix</content-item-type>
          <bookseq>23</bookseq>
          <fpage>458</fpage>
          <lpage>459</lpage>
          <numpages>2</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>The supportive details of the example presented in the electrical power load problem and air traffic problem are given in this appendix.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">A0250</compound-classification-code-part><compound-classification-code-part type="text">Probability theory, stochastic processes, and statistics</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">air traffic</keyword>
            <keyword source="Inspec">load forecasting</keyword>
            <keyword source="Inspec">time series</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">electrical power load problem</keyword>
            <keyword source="uncontrolled">air traffic problem</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_appendix7b</content-item-id>
          <doi>10.1049/PBCE052E_appendix7b</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Appendix 7B: Data on ozone column thickness</title>
          <search-title>Appendix 7B: Data on ozone column thickness</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>appendix</content-item-type>
          <bookseq>24</bookseq>
          <fpage>460</fpage>
          <lpage>460</lpage>
          <numpages>1</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>The atmospheric ozone column thickness in the atmosphere measured at Arosa, Switzerland, is reproduced here from P. Bloomfield. 1985.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">A0130L</compound-classification-code-part><compound-classification-code-part type="text">Collections of physical data, tables</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">atmospheric composition</keyword>
            <keyword source="Inspec">ozone</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">atmospheric ozone column thickness</keyword>
            <keyword source="uncontrolled">Arosa</keyword>
            <keyword source="uncontrolled">Switzerland</keyword>
            <keyword source="uncontrolled">AD 1931 to 1971</keyword>
            <keyword source="uncontrolled">O<emph type="inferior">3</emph></keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_appendix7c</content-item-id>
          <doi>10.1049/PBCE052E_appendix7c</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Appendix 7C: Data on atmospheric concentration of carbon dioxide</title>
          <search-title>Appendix 7C: Data on atmospheric concentration of carbon dioxide</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>appendix</content-item-type>
          <bookseq>25</bookseq>
          <fpage>461</fpage>
          <lpage>461</lpage>
          <numpages>1</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>The atmospheric concentration of carbon dioxide in parts per million for 22 consecutive years from 1959 to 1980 measured at the Mount Mauna Loa observatory in Hawaii is given in a table; the data are presented row-wise for each year (from January to December) starting from 1959.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">A0130L</compound-classification-code-part><compound-classification-code-part type="text">Collections of physical data, tables</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">atmospheric composition</keyword>
            <keyword source="Inspec">carbon compounds</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">atmospheric concentration of carbon dioxide</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_appendix7d</content-item-id>
          <doi>10.1049/PBCE052E_appendix7d</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Appendix 7D: Data on electrical power load on a substation</title>
          <search-title>Appendix 7D: Data on electrical power load on a substation</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>appendix</content-item-type>
          <bookseq>26</bookseq>
          <fpage>462</fpage>
          <lpage>463</lpage>
          <numpages>2</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>The electrical power load on a substation for 25 consecutive mondays of the year 1983 are presented here. The hourly data for arranged row-wise in the following table for the consecutive mondays.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">B8375</compound-classification-code-part><compound-classification-code-part type="text">Substations</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">load (electric)</keyword>
            <keyword source="Inspec">substations</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">electrical power load data</keyword>
            <keyword source="uncontrolled">substation</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_appendix7e</content-item-id>
          <doi>10.1049/PBCE052E_appendix7e</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Appendix 7E: Data on unemployment in Germany</title>
          <search-title>Appendix 7E: Data on unemployment in Germany</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>appendix</content-item-type>
          <bookseq>27</bookseq>
          <fpage>464</fpage>
          <lpage>464</lpage>
          <numpages>1</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>In this paper the monthly figures on the number of people unemployed in Germany during the period 1948 to 1978 are given. The monthly data for each year are presented row-wise.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">A0130L</compound-classification-code-part><compound-classification-code-part type="text">Collections of physical data, tables</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">collections of physical data</keyword>
            <keyword source="Inspec">unemployment</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">unemployment</keyword>
            <keyword source="uncontrolled">Germany</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_appendix7f</content-item-id>
          <doi>10.1049/PBCE052E_appendix7f</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Appendix 7F: Data on rainfall in India</title>
          <search-title>Appendix 7F: Data on rainfall in India</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>appendix</content-item-type>
          <bookseq>28</bookseq>
          <fpage>465</fpage>
          <lpage>466</lpage>
          <numpages>2</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>In India, the summer monsoon rainfall shows considerable spatial variability. The data presented here concern spatially coherent rainfall pattern over the north-western and central parts of Indian covering about 55% of the total area of the country. The monthly rainfall data at 14 meteorological sub-divisions over the years 1871-1990 have been used by Parthasarathy, Rupa Kumar and Munot (1993) to prepare the homogeneous rainfall data set. The data from 1940 to 1990 are extracted and presented here.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">A0130L</compound-classification-code-part><compound-classification-code-part type="text">Collections of physical data, tables</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">climatology</keyword>
            <keyword source="Inspec">rain</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">summer monsoon rainfall</keyword>
            <keyword source="uncontrolled">spatial variability</keyword>
            <keyword source="uncontrolled">spatially coherent rainfall pattern</keyword>
            <keyword source="uncontrolled">monthly rainfall data</keyword>
            <keyword source="uncontrolled">meteorological subdivisions</keyword>
            <keyword source="uncontrolled">AD 1871 to 1990</keyword>
            <keyword source="uncontrolled">homogeneous rainfall data set</keyword>
            <keyword source="uncontrolled">homogeneous Indian rainfall</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_appendix8a</content-item-id>
          <doi>10.1049/PBCE052E_appendix8a</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Appendix 8A: Data on yearly averaged sunspot numbers</title>
          <search-title>Appendix 8A: Data on yearly averaged sunspot numbers</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>appendix</content-item-type>
          <bookseq>29</bookseq>
          <fpage>467</fpage>
          <numpages>1</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>The count the number of spots on the sun's surface is of interest in Astronomy and Climatology for geophysical reasons; the series is also of interest to time series analysts for the time-varying nature of the series. The daily observations from more than 50 observatories are used to arrive at the relative values of the sunspot numbers; the yearly averaged values for the years 1700 to 1987 are presented here.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">A0130L</compound-classification-code-part><compound-classification-code-part type="text">Collections of physical data, tables</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">climatology</keyword>
            <keyword source="Inspec">solar-terrestrial relationships</keyword>
            <keyword source="Inspec">sunspots</keyword>
            <keyword source="Inspec">time series</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">sun surface</keyword>
            <keyword source="uncontrolled">astronomy</keyword>
            <keyword source="uncontrolled">climatology</keyword>
            <keyword source="uncontrolled">time series analysts</keyword>
            <keyword source="uncontrolled">yearly averaged sunspot numbers</keyword>
            <keyword source="uncontrolled">AD 1700 to 1987</keyword>
          </keywords>
        </vocabs>
        <funding-grp><access type="free"/></funding-grp>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_appendix8b</content-item-id>
          <doi>10.1049/PBCE052E_appendix8b</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Appendix 8B: Data on variations in the rotation rate of Earth</title>
          <search-title>Appendix 8B: Data on variations in the rotation rate of Earth</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>appendix</content-item-type>
          <bookseq>30</bookseq>
          <fpage>468</fpage>
          <lpage>468</lpage>
          <numpages>1</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>The variations in the rate of rotation of the Earth, are reproduced. The series has been of interest for thepossible relationship with the sunspot numbers (Appendix 8A) and in general with the planetary system. Yearly data for the period 1820 to 1970 are presented here.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">A0130L</compound-classification-code-part><compound-classification-code-part type="text">Collections of physical data, tables</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">Earth rotation</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">Earth rotation rate variations</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_appendix9</content-item-id>
          <doi>10.1049/PBCE052E_appendix9</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Appendix 9: Data on COD process in the Osaka Bay</title>
          <search-title>Appendix 9: Data on COD process in the Osaka Bay</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>appendix</content-item-type>
          <bookseq>31</bookseq>
          <fpage>469</fpage>
          <lpage>470</lpage>
          <numpages>2</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>The chemical oxygen demand (COD) can be considered to be an index of water pollution in the sea. COD concentration is monitored at a number of stations in the Osaka bay along with water temperature, transparency and dissolved oxygen concentration. Altogether 84 sets of monthly data are available, corresponding to the years 1976 to 1983. The output variable is the COD concentration, which is related to the input variables: water temperature, water transparency and dissolved oxygen concentration. The observed values of filtered COD (i.e. COD values of sea water free from suspended materials) are also presented.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">A0130L</compound-classification-code-part><compound-classification-code-part type="text">Collections of physical data, tables</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">ocean chemistry</keyword>
            <keyword source="Inspec">ocean temperature</keyword>
            <keyword source="Inspec">oxygen</keyword>
            <keyword source="Inspec">underwater optics</keyword>
            <keyword source="Inspec">water pollution measurement</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">COD process</keyword>
            <keyword source="uncontrolled">Osaka bay</keyword>
            <keyword source="uncontrolled">Japan</keyword>
            <keyword source="uncontrolled">chemical oxygen demand</keyword>
            <keyword source="uncontrolled">seawater pollution index</keyword>
            <keyword source="uncontrolled">AD 1976 to 1983</keyword>
            <keyword source="uncontrolled">water temperature</keyword>
            <keyword source="uncontrolled">water transparency</keyword>
            <keyword source="uncontrolled">dissolved oxygen concentration</keyword>
            <keyword source="uncontrolled">O</keyword>
          </keywords>
        </vocabs>
        <funding-grp><access type="free"/></funding-grp>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_appendix10</content-item-id>
          <doi>10.1049/PBCE052E_appendix10</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Appendix 10: Generalized delta rule</title>
          <search-title>Appendix 10: Generalized delta rule</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>appendix</content-item-type>
          <bookseq>32</bookseq>
          <fpage>471</fpage>
          <lpage>473</lpage>
          <numpages>3</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>The derivation of the generalized delta rule (GDR) which is due to Rumelhart, Hinton and Williams (1986) is presented here. GDR gives an expression for the adaptive change in the weights on the interconnection between the nodes minimizing the cost. GDR is based on the gradient descent algorithm, according to which the adaptation in the weights is proportional to the gradient error.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">C1330</compound-classification-code-part><compound-classification-code-part type="text">Optimal control</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">gradient methods</keyword>
            <keyword source="Inspec">predictive control</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">generalized delta rule</keyword>
            <keyword source="uncontrolled">adaptive prediction</keyword>
            <keyword source="uncontrolled">predictive control</keyword>
            <keyword source="uncontrolled">GDR</keyword>
            <keyword source="uncontrolled">adaptive change</keyword>
            <keyword source="uncontrolled">gradient descent algorithm</keyword>
            <keyword source="uncontrolled">gradient error</keyword>
          </keywords>
        </vocabs>
        <funding-grp><access type="free"/></funding-grp>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_appendix11</content-item-id>
          <doi>10.1049/PBCE052E_appendix11</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Appendix 11: SVR spectrum</title>
          <search-title>Appendix 11: SVR spectrum</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>appendix</content-item-type>
          <bookseq>33</bookseq>
          <fpage>474</fpage>
          <lpage>478</lpage>
          <numpages>5</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>SVR spectrum is a method of determining the period length of periodic components present, if any, in any signal or data sequence; the periodic components need not be sinusoidal. The data &lt;y(k)&gt; are arranged into the consecutive rows of a matrix (A) which is singular value decomposed; the generic term Singular Value Ratio (SVR) spectrum stands for the spectrum of a function (usually squared ratio) of the most dominant and other singular values against varying row lengths of the data matrix.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">A0210</compound-classification-code-part><compound-classification-code-part type="text">Algebra, set theory, and graph theory</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">singular value decomposition</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">SVR spectrum</keyword>
            <keyword source="uncontrolled">periodic components</keyword>
            <keyword source="uncontrolled">matrix rows</keyword>
            <keyword source="uncontrolled">singular value ratio spectrum</keyword>
            <keyword source="uncontrolled">data matrix</keyword>
            <keyword source="uncontrolled">data sequence</keyword>
            <keyword source="uncontrolled">signal sequence</keyword>
            <keyword source="uncontrolled">singular value decomposition</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_appendix12a</content-item-id>
          <doi>10.1049/PBCE052E_appendix12a</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Appendix 12A: Systems and controls basics</title>
          <search-title>Appendix 12A: Systems and controls basics</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>appendix</content-item-type>
          <bookseq>34</bookseq>
          <fpage>479</fpage>
          <lpage>484</lpage>
          <numpages>5</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>Some basic concepts related to systems, models and control methods are introduced here. Every system or process is, by itself, a continuous time process. However, for considerations related to measurement and computation, process measurements are often recorded at discrete-time intervals, and the monitored process is loosely called a discrete-time process.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">C1340D</compound-classification-code-part><compound-classification-code-part type="text">Discrete control systems</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">continuous time systems</keyword>
            <keyword source="Inspec">discrete time systems</keyword>
            <keyword source="Inspec">robust control</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">continuous time process</keyword>
            <keyword source="uncontrolled">process measurement</keyword>
            <keyword source="uncontrolled">discrete time process</keyword>
            <keyword source="uncontrolled">control method</keyword>
            <keyword source="uncontrolled">discrete time interval</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_appendix12b</content-item-id>
          <doi>10.1049/PBCE052E_appendix12b</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Appendix 12B: Smith predictor</title>
          <search-title>Appendix 12B: Smith predictor</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>appendix</content-item-type>
          <bookseq>35</bookseq>
          <fpage>485</fpage>
          <lpage>487</lpage>
          <numpages>3</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>One of the fundamental works in predictive control is by Smith (1957), who designed a controller essentially free from the effects of the time delay. A typical process shows an inherent time delay between the input u, and the process output y. Let the time delay be expressed as G<emph type="inferior">d</emph>, given by exp(-s&#x03C4;), in continuous time, s being the Laplace operator. The control action can at best force the output to be equal to the set point in a time equal to the dead time of the process. Faster control performance is not possible. Under-estimation of the time delay and unnecessary control action can lead to instability.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">C1340J</compound-classification-code-part><compound-classification-code-part type="text">Distributed parameter control systems</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">continuous time systems</keyword>
            <keyword source="Inspec">control system synthesis</keyword>
            <keyword source="Inspec">delay systems</keyword>
            <keyword source="Inspec">Laplace equations</keyword>
            <keyword source="Inspec">predictive control</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">Smith predictor</keyword>
            <keyword source="uncontrolled">predictive control</keyword>
            <keyword source="uncontrolled">controller design</keyword>
            <keyword source="uncontrolled">time delay</keyword>
            <keyword source="uncontrolled">continuous time</keyword>
            <keyword source="uncontrolled">Laplace operator</keyword>
            <keyword source="uncontrolled">dead time</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_appendix13a</content-item-id>
          <doi>10.1049/PBCE052E_appendix13a</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Appendix 13A: Derivation of state-space deterministic LQ control</title>
          <search-title>Appendix 13A: Derivation of state-space deterministic LQ control</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>appendix</content-item-type>
          <bookseq>36</bookseq>
          <fpage>488</fpage>
          <lpage>490</lpage>
          <numpages>3</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>In this appendix the state-space formulation of the deterministic LQ control problem is presented. A multi-input multi-output process is considered. The derivation is based on dynamic programming, which was developed by Bellman in 1953 (Bellman and Dreyfus, 1962). The derivation can be easily simplified to the single-input single-output case.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">C1330</compound-classification-code-part><compound-classification-code-part type="text">Optimal control</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">dynamic programming</keyword>
            <keyword source="Inspec">linear quadratic control</keyword>
            <keyword source="Inspec">MIMO systems</keyword>
            <keyword source="Inspec">state-space methods</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">state-space deterministic</keyword>
            <keyword source="uncontrolled">LQ control</keyword>
            <keyword source="uncontrolled">multiple input multiple output process</keyword>
            <keyword source="uncontrolled">dynamic programming</keyword>
            <keyword source="uncontrolled">single input single output</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_appendix13b</content-item-id>
          <doi>10.1049/PBCE052E_appendix13b</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Appendix 13B: Transmittance matrix: formulation and implementation</title>
          <search-title>Appendix 13B: Transmittance matrix: formulation and implementation</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>appendix</content-item-type>
          <bookseq>37</bookseq>
          <fpage>491</fpage>
          <lpage>497</lpage>
          <numpages>7</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>Use of transmittance matrices offers a straightforward method for simplifying a polynomial matrix multiplication problem into an ordinary matrix multiplication problem. The transmittance matrix formulation can be very useful in per forming state estimation. This appendix discusses the vector formulation of the transmittance matrix and its application for state estimation.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">A0210</compound-classification-code-part><compound-classification-code-part type="text">Algebra, set theory, and graph theory</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">matrix multiplication</keyword>
            <keyword source="Inspec">polynomial matrices</keyword>
            <keyword source="Inspec">vectors</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">polynomial matrix multiplication</keyword>
            <keyword source="uncontrolled">state estimation</keyword>
            <keyword source="uncontrolled">vector formulation</keyword>
            <keyword source="uncontrolled">FORTRAN implementation</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_appendix13c</content-item-id>
          <doi>10.1049/PBCE052E_appendix13c</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Appendix 13C: Covariance time update using U-D factorization</title>
          <search-title>Appendix 13C: Covariance time update using U-D factorization</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>appendix</content-item-type>
          <bookseq>38</bookseq>
          <fpage>498</fpage>
          <lpage>501</lpage>
          <numpages>4</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>U-D covariance factorization is attractive because of numerical robustness, algorithmic simplicity and computational efficiency. Bierman (1977, p. 124) studies the general covariance time update problem: P = &#x03A6;P*&#x03A6;<emph type="superior">T</emph> + GQG<emph type="superior">T</emph>, where U-D factors of P*, P* = U*D*U*<emph type="superior">T</emph>, are given and the updated U-D factors are computed. A particular form of the U-D covariance update problem relating to the LQ state-space controller is discussed in Clarke et. al. (1985), where the vector implementation is also presented; the material presented here is largely based on this reference.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">C4140</compound-classification-code-part><compound-classification-code-part type="text">Linear algebra (numerical analysis)</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">computational complexity</keyword>
            <keyword source="Inspec">covariance matrices</keyword>
            <keyword source="Inspec">matrix decomposition</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">covariance time update</keyword>
            <keyword source="uncontrolled">U-D covariance factorization</keyword>
            <keyword source="uncontrolled">numerical robustness</keyword>
            <keyword source="uncontrolled">algorithmic simplicity</keyword>
            <keyword source="uncontrolled">computational efficiency</keyword>
            <keyword source="uncontrolled">LQ state-space controller</keyword>
            <keyword source="uncontrolled">vector implementation</keyword>
          </keywords>
        </vocabs>
        <funding-grp><access type="free"/></funding-grp>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_appendix14a</content-item-id>
          <doi>10.1049/PBCE052E_appendix14a</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Appendix 14A: Low-pass filter</title>
          <search-title>Appendix 14A: Low-pass filter</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>appendix</content-item-type>
          <bookseq>39</bookseq>
          <fpage>502</fpage>
          <lpage>505</lpage>
          <numpages>4</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>A low-pass filter is a frequency domain filter, which allows the specified low-frequency part of the signal or data sequence to pass through, whereas the higher frequency components are attenuated. The objective is to separate from the data undesirable high frequency components, which may be due to external disturbances or noise. The filter may be characterized by the pass-band, the transition band, the stop-band and the gain or the pass-band magnitude. The smaller the transition region, the sharper is the separation between the frequency components passed and those attenuated.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">B6140B</compound-classification-code-part><compound-classification-code-part type="text">Filtering methods in signal processing</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">Butterworth filters</keyword>
            <keyword source="Inspec">low-pass filters</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">low-pass filter</keyword>
            <keyword source="uncontrolled">frequency domain filter</keyword>
            <keyword source="uncontrolled">signal sequence</keyword>
            <keyword source="uncontrolled">data sequence</keyword>
            <keyword source="uncontrolled">pass-band magnitude</keyword>
            <keyword source="uncontrolled">transition band magnitude</keyword>
            <keyword source="uncontrolled">stop-band magnitude</keyword>
            <keyword source="uncontrolled">gain magnitude</keyword>
            <keyword source="uncontrolled">frequency response</keyword>
            <keyword source="uncontrolled">cut-off sharpness</keyword>
            <keyword source="uncontrolled">Butterworth filter</keyword>
            <keyword source="uncontrolled">Chebyshev filter</keyword>
          </keywords>
        </vocabs>
        <funding-grp><access type="free"/></funding-grp>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_appendix14b</content-item-id>
          <doi>10.1049/PBCE052E_appendix14b</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Appendix 14B: Permeability data</title>
          <search-title>Appendix 14B: Permeability data</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>appendix</content-item-type>
          <bookseq>40</bookseq>
          <fpage>506</fpage>
          <lpage>506</lpage>
          <numpages>1</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>This section of the book presents sets of data that are 2-minutely recorded permeability measurements of the green-mix permeability in the process of iron-ore sintering collected from an iron and steel plant.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">E3636</compound-classification-code-part><compound-classification-code-part type="text">Metallurgical industries</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">iron</keyword>
            <keyword source="Inspec">minerals</keyword>
            <keyword source="Inspec">permeability</keyword>
            <keyword source="Inspec">sintering</keyword>
            <keyword source="Inspec">steel industry</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">iron-ore sintering</keyword>
            <keyword source="uncontrolled">permeability measurement</keyword>
            <keyword source="uncontrolled">green-mix permeability</keyword>
            <keyword source="uncontrolled">iron plant</keyword>
            <keyword source="uncontrolled">steel plant</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_appendix14c</content-item-id>
          <doi>10.1049/PBCE052E_appendix14c</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Appendix 14C: Composite data on maternal ECG containing fetal ECG</title>
          <search-title>Appendix 14C: Composite data on maternal ECG containing fetal ECG</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>appendix</content-item-type>
          <bookseq>41</bookseq>
          <fpage>507</fpage>
          <lpage>508</lpage>
          <numpages>2</numpages>
        </content-item-pubinfo>
        <abstract>
          <p>This appendix discussed the composite maternal and fetal ECG during gestation period by downsampling the digitized data.</p>
        </abstract>
        <vocabs>
          <classification-codes source="Inspec-class">
            <compound-classification-code><compound-classification-code-part type="code">A8730C</compound-classification-code-part><compound-classification-code-part type="text">Electrical activity in neurophysiological processes</compound-classification-code-part></compound-classification-code>
          </classification-codes>
          <keywords source="Inspec">
            <keyword source="Inspec">electrocardiography</keyword>
            <keyword source="Inspec">obstetrics</keyword>
          </keywords>
          <keywords source="uncontrolled">
            <keyword source="uncontrolled">composite data</keyword>
            <keyword source="uncontrolled">maternal ECG</keyword>
            <keyword source="uncontrolled">fetal ECG</keyword>
            <keyword source="uncontrolled">gestation</keyword>
            <keyword source="uncontrolled">downsampling</keyword>
            <keyword source="uncontrolled">digitized data</keyword>
          </keywords>
        </vocabs>
      </content-item-metadata>
    </content-item>
    <content-item>
      <content-item-metadata>
        <content-item-identifiers>
          <content-item-id>PBCE052E_backmatter</content-item-id>
          <doi>10.1049/PBCE052E_bm</doi>
        </content-item-identifiers>
        <titlegrp>
          <title>Back Matter</title>
          <search-title>Back Matter</search-title>
        </titlegrp>
        <content-item-pubinfo>
          <content-item-type>back matter</content-item-type>
          <bookseq>42</bookseq>
          <section-head level="1">Author index</section-head>
          <section-head level="1">Subject index</section-head>
          <fpage>267</fpage>
        </content-item-pubinfo>
        <funding-grp><access type="free"/></funding-grp>
      </content-item-metadata>
    </content-item>
  </body>
</ebook>
